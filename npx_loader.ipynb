{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# edgar_npx_downloader_improved.py\n",
    "##################################################\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# 1. Global Configuration & Setup\n",
    "# ------------------------------------------------\n",
    "TARGET_YEAR = 2024\n",
    "MAX_DOWNLOADS = 25  # can be set to None to download all\n",
    "MASTER_INDEX_DIR = \"./edgar_index\"\n",
    "NPX_DOWNLOAD_DIR = \"./npx_filings\"\n",
    "#HEADERS = {\"User-Agent\": \"N-PX-Downloader (myemail@domain.com)\"}\n",
    "HEADERS = {\"User-Agent\": \"PythonRequests/3.0 (Generic Scraper)\"}\n",
    "\n",
    "# For robust networking\n",
    "def create_requests_session(\n",
    "    retries: int = 3, backoff_factor: float = 0.3, status_forcelist=(500, 502, 503, 504)\n",
    ") -> requests.Session:\n",
    "    \"\"\"\n",
    "    Create a requests Session with retry logic for handling transient errors.\n",
    "    \"\"\"\n",
    "    session = requests.Session()\n",
    "    retry = Retry(\n",
    "        total=retries,\n",
    "        read=retries,\n",
    "        connect=retries,\n",
    "        backoff_factor=backoff_factor,\n",
    "        status_forcelist=status_forcelist,\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount(\"http://\", adapter)\n",
    "    session.mount(\"https://\", adapter)\n",
    "    return session\n",
    "\n",
    "# We'll use a single session throughout the script\n",
    "REQUESTS_SESSION = create_requests_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# 2. Master Index Download & Parsing\n",
    "# ------------------------------------------------\n",
    "\n",
    "def download_master_index(year: int, quarter: int, base_dir: str = MASTER_INDEX_DIR) -> str:\n",
    "    \"\"\"\n",
    "    Downloads the master index for the specified year & quarter,\n",
    "    saving it locally as {base_dir}/{year}_QTR{quarter}_master.idx.\n",
    "    Returns the local filepath or \"\" on failure.\n",
    "    \"\"\"\n",
    "    url = f\"https://www.sec.gov/Archives/edgar/full-index/{year}/QTR{quarter}/master.idx\"\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "    local_filename = os.path.join(base_dir, f\"{year}_QTR{quarter}_master.idx\")\n",
    "\n",
    "    # Check if file already exists to avoid re-downloading (resume logic)\n",
    "    if os.path.exists(local_filename) and os.path.getsize(local_filename) > 0:\n",
    "        print(f\"File already exists, skipping download: {local_filename}\")\n",
    "        return local_filename\n",
    "\n",
    "    print(f\"Downloading: {url}\")\n",
    "    try:\n",
    "        response = REQUESTS_SESSION.get(url, headers=HEADERS, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            with open(local_filename, \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"Saved to: {local_filename}\")\n",
    "            return local_filename\n",
    "        else:\n",
    "            print(f\"Failed to retrieve {url} [HTTP {response.status_code}].\")\n",
    "            return \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to {url}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def parse_master_index(idx_filepath: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parses a local .idx master index file and returns a DataFrame.\n",
    "    DataFrame columns: [cik, company_name, form_type, date_filed, filename].\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    if not os.path.exists(idx_filepath) or os.path.getsize(idx_filepath) == 0:\n",
    "        print(f\"Index file not found or empty: {idx_filepath}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Attempt to read lines\n",
    "    try:\n",
    "        with open(idx_filepath, \"r\", encoding=\"latin-1\") as f:\n",
    "            lines = f.readlines()\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to read {idx_filepath}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Find header line\n",
    "    start_idx = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.strip().startswith(\"CIK|Company Name|Form Type|Date Filed|Filename\"):\n",
    "            start_idx = i + 1\n",
    "            break\n",
    "\n",
    "    if start_idx is None:\n",
    "        print(f\"Could not find the data header in: {idx_filepath}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Parse lines from start_idx onward\n",
    "    for line in lines[start_idx:]:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        parts = line.split(\"|\")\n",
    "        if len(parts) < 5:\n",
    "            continue\n",
    "        cik, company_name, form_type, date_filed, filename = parts[:5]\n",
    "        records.append({\n",
    "            \"cik\": cik,\n",
    "            \"company_name\": company_name,\n",
    "            \"form_type\": form_type,\n",
    "            \"date_filed\": date_filed,\n",
    "            \"filename\": filename\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_all_npx_for_year(\n",
    "    year: int,\n",
    "    base_dir: str = MASTER_INDEX_DIR,\n",
    "    output_csv: str = \"npx_list.csv\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Downloads & parses QTR1-QTR4 master indexes for the given year,\n",
    "    filters for N-PX form types, saves combined results to a CSV:\n",
    "    {base_dir}/{output_csv}. Returns the N-PX DataFrame.\n",
    "    \"\"\"\n",
    "    combined_df = pd.DataFrame()\n",
    "\n",
    "    for quarter in [1, 2, 3, 4]:\n",
    "        idx_path = download_master_index(year, quarter, base_dir=base_dir)\n",
    "        if not idx_path:\n",
    "            # No file or failed download\n",
    "            continue\n",
    "        df_q = parse_master_index(idx_path)\n",
    "        if df_q.empty:\n",
    "            continue\n",
    "        combined_df = pd.concat([combined_df, df_q], ignore_index=True)\n",
    "\n",
    "    if combined_df.empty:\n",
    "        print(\"No data found for the entire year.\")\n",
    "        return combined_df\n",
    "\n",
    "    # Filter for N-PX only\n",
    "    mask_npx = combined_df[\"form_type\"].str.upper() == \"N-PX\"\n",
    "    npx_df = combined_df[mask_npx].copy()\n",
    "\n",
    "    # Save to CSV\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "    output_path = os.path.join(base_dir, output_csv)\n",
    "    npx_df.to_csv(output_path, index=False)\n",
    "    print(f\"Saved N-PX listings to {output_path} (Count: {len(npx_df)})\")\n",
    "\n",
    "    return npx_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# 3. Download N-PX Filings With Improvements\n",
    "# ------------------------------------------------\n",
    "\n",
    "def download_npx_filings(\n",
    "    npx_df: pd.DataFrame,\n",
    "    max_downloads: int = 10,\n",
    "    output_dir: str = NPX_DOWNLOAD_DIR,\n",
    "    random_sample: bool = False,\n",
    "    min_sleep: float = 0.5,\n",
    "    max_sleep: float = 1.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Download up to 'max_downloads' N-PX filings from npx_df.\n",
    "    - Resumes by skipping files that already exist locally.\n",
    "    - Allows random sampling of the data set.\n",
    "    - Rate-limits requests with random sleep intervals [min_sleep, max_sleep].\n",
    "    \"\"\"\n",
    "    if npx_df.empty:\n",
    "        print(\"No N-PX filings in the DataFrame.\")\n",
    "        return\n",
    "\n",
    "    # If max_downloads=None, download them all\n",
    "    total_filings = len(npx_df)\n",
    "    if max_downloads is None or max_downloads > total_filings:\n",
    "        max_downloads = total_filings\n",
    "\n",
    "    # Decide how to pick the subset\n",
    "    if random_sample:\n",
    "        # random sample of size max_downloads\n",
    "        subset_df = npx_df.sample(n=max_downloads, random_state=42).reset_index(drop=True)\n",
    "        print(f\"Randomly sampling {max_downloads} out of {total_filings} possible filings.\")\n",
    "    else:\n",
    "        # just take the first N rows\n",
    "        subset_df = npx_df.head(max_downloads)\n",
    "        print(f\"Taking top {max_downloads} of {total_filings} filings.\")\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for idx, row in subset_df.iterrows():\n",
    "        filename = row[\"filename\"].strip()\n",
    "        form_type = row[\"form_type\"].strip()\n",
    "        date_filed = row[\"date_filed\"].strip()\n",
    "\n",
    "        full_url = f\"https://www.sec.gov/Archives/{filename}\"\n",
    "        local_name = f\"{date_filed}_{form_type}_{os.path.basename(filename)}\"\n",
    "        local_path = os.path.join(output_dir, local_name)\n",
    "\n",
    "        # Resume/Skip logic\n",
    "        if os.path.exists(local_path) and os.path.getsize(local_path) > 0:\n",
    "            print(f\"File already exists, skipping: {local_path}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nDownloading: {full_url}\")\n",
    "        try:\n",
    "            r = REQUESTS_SESSION.get(full_url, headers=HEADERS, timeout=10)\n",
    "            if r.status_code == 200:\n",
    "                with open(local_path, \"wb\") as f:\n",
    "                    f.write(r.content)\n",
    "                print(f\"Saved to: {local_path}\")\n",
    "            else:\n",
    "                print(f\"Failed to download [HTTP {r.status_code}].\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading {full_url}: {e}\")\n",
    "\n",
    "        # Rate-limiting with random sleep\n",
    "        sleep_duration = random.uniform(min_sleep, max_sleep)\n",
    "        time.sleep(sleep_duration)\n",
    "\n",
    "    print(\"\\nDownload process complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: https://www.sec.gov/Archives/edgar/full-index/2024/QTR1/master.idx\n",
      "Saved to: ./edgar_index\\2024_QTR1_master.idx\n",
      "Downloading: https://www.sec.gov/Archives/edgar/full-index/2024/QTR2/master.idx\n",
      "Saved to: ./edgar_index\\2024_QTR2_master.idx\n",
      "Downloading: https://www.sec.gov/Archives/edgar/full-index/2024/QTR3/master.idx\n",
      "Saved to: ./edgar_index\\2024_QTR3_master.idx\n",
      "Downloading: https://www.sec.gov/Archives/edgar/full-index/2024/QTR4/master.idx\n",
      "Saved to: ./edgar_index\\2024_QTR4_master.idx\n",
      "Saved N-PX listings to ./edgar_index\\npx_2024_list.csv (Count: 10321)\n",
      "Randomly sampling 25 out of 10321 possible filings.\n",
      "\n",
      "Downloading: https://www.sec.gov/Archives/edgar/data/1511985/0001085146-24-003669.txt\n",
      "Saved to: ./npx_filings\\2024-08-09_N-PX_0001085146-24-003669.txt\n",
      "\n",
      "Downloading: https://www.sec.gov/Archives/edgar/data/1639997/0001376474-24-000319.txt\n",
      "Saved to: ./npx_filings\\2024-07-16_N-PX_0001376474-24-000319.txt\n",
      "\n",
      "Downloading: https://www.sec.gov/Archives/edgar/data/1826136/0001172661-24-003627.txt\n",
      "Saved to: ./npx_filings\\2024-08-20_N-PX_0001172661-24-003627.txt\n",
      "\n",
      "Downloading: https://www.sec.gov/Archives/edgar/data/1846352/0001846352-24-000006.txt\n",
      "Saved to: ./npx_filings\\2024-08-27_N-PX_0001846352-24-000006.txt\n",
      "\n",
      "Downloading: https://www.sec.gov/Archives/edgar/data/1004655/0001104659-24-094403.txt\n",
      "Saved to: ./npx_filings\\2024-08-29_N-PX_0001104659-24-094403.txt\n",
      "\n",
      "Downloading: https://www.sec.gov/Archives/edgar/data/710826/0001021408-24-005385.txt\n",
      "Saved to: ./npx_filings\\2024-08-28_N-PX_0001021408-24-005385.txt\n",
      "\n",
      "Downloading: https://www.sec.gov/Archives/edgar/data/2011250/0002011250-24-000010.txt\n",
      "Saved to: ./npx_filings\\2024-08-30_N-PX_0002011250-24-000010.txt\n",
      "\n",
      "Downloading: https://www.sec.gov/Archives/edgar/data/1276470/0001013594-24-000698.txt\n",
      "Saved to: ./npx_filings\\2024-08-27_N-PX_0001013594-24-000698.txt\n",
      "\n",
      "Downloading: https://www.sec.gov/Archives/edgar/data/52848/0001104659-24-094321.txt\n",
      "Saved to: ./npx_filings\\2024-08-29_N-PX_0001104659-24-094321.txt\n",
      "\n",
      "Downloading: https://www.sec.gov/Archives/edgar/data/1109228/0001420506-24-001838.txt\n",
      "Saved to: ./npx_filings\\2024-08-28_N-PX_0001420506-24-001838.txt\n",
      "\n",
      "Downloading: https://www.sec.gov/Archives/edgar/data/2011563/0000919574-24-005220.txt\n",
      "Saved to: ./npx_filings\\2024-08-30_N-PX_0000919574-24-005220.txt\n",
      "\n",
      "Downloading: https://www.sec.gov/Archives/edgar/data/1964809/0001705819-24-000051.txt\n",
      "Saved to: ./npx_filings\\2024-08-26_N-PX_0001705819-24-000051.txt\n",
      "\n",
      "Downloading: https://www.sec.gov/Archives/edgar/data/1066241/0001162044-24-001017.txt\n",
      "Saved to: ./npx_filings\\2024-09-10_N-PX_0001162044-24-001017.txt\n",
      "\n",
      "Downloading: https://www.sec.gov/Archives/edgar/data/1511699/0001438934-24-001919.txt\n",
      "Saved to: ./npx_filings\\2024-09-03_N-PX_0001438934-24-001919.txt\n",
      "\n",
      "Downloading: https://www.sec.gov/Archives/edgar/data/830487/0001021408-24-002025.txt\n",
      "Saved to: ./npx_filings\\2024-08-16_N-PX_0001021408-24-002025.txt\n",
      "\n",
      "Downloading: https://www.sec.gov/Archives/edgar/data/1993888/0001993888-24-000009.txt\n",
      "Saved to: ./npx_filings\\2024-08-30_N-PX_0001993888-24-000009.txt\n",
      "\n",
      "Downloading: https://www.sec.gov/Archives/edgar/data/823621/0001172661-24-003746.txt\n",
      "Saved to: ./npx_filings\\2024-08-27_N-PX_0001172661-24-003746.txt\n",
      "\n",
      "Downloading: https://www.sec.gov/Archives/edgar/data/1924868/0001438934-24-001631.txt\n",
      "Saved to: ./npx_filings\\2024-08-30_N-PX_0001438934-24-001631.txt\n",
      "\n",
      "Downloading: https://www.sec.gov/Archives/edgar/data/1910398/0001437749-24-026024.txt\n",
      "Saved to: ./npx_filings\\2024-08-12_N-PX_0001437749-24-026024.txt\n",
      "\n",
      "Downloading: https://www.sec.gov/Archives/edgar/data/1593547/0001135428-24-000141.txt\n",
      "Saved to: ./npx_filings\\2024-08-26_N-PX_0001135428-24-000141.txt\n",
      "\n",
      "Downloading: https://www.sec.gov/Archives/edgar/data/1314414/0001580642-24-004662.txt\n",
      "Saved to: ./npx_filings\\2024-08-20_N-PX_0001580642-24-004662.txt\n",
      "\n",
      "Downloading: https://www.sec.gov/Archives/edgar/data/1818416/0000930413-24-002632.txt\n",
      "Saved to: ./npx_filings\\2024-08-29_N-PX_0000930413-24-002632.txt\n",
      "\n",
      "Downloading: https://www.sec.gov/Archives/edgar/data/1742647/0001398344-24-016928.txt\n",
      "Saved to: ./npx_filings\\2024-08-30_N-PX_0001398344-24-016928.txt\n",
      "\n",
      "Downloading: https://www.sec.gov/Archives/edgar/data/1694896/0001172661-24-003023.txt\n",
      "Saved to: ./npx_filings\\2024-08-01_N-PX_0001172661-24-003023.txt\n",
      "\n",
      "Downloading: https://www.sec.gov/Archives/edgar/data/1915315/0001915315-24-000003.txt\n",
      "Saved to: ./npx_filings\\2024-07-17_N-PX_0001915315-24-000003.txt\n",
      "\n",
      "Download process complete.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------\n",
    "# 4. Putting It All Together\n",
    "# ------------------------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 4.1: Gather all N-PX for the chosen year\n",
    "    npx_df = get_all_npx_for_year(\n",
    "        year=TARGET_YEAR,\n",
    "        base_dir=MASTER_INDEX_DIR,\n",
    "        output_csv=f\"npx_{TARGET_YEAR}_list.csv\"\n",
    "    )\n",
    "\n",
    "    # 4.2: If we have any N-PX records, download them\n",
    "    if not npx_df.empty:\n",
    "        download_npx_filings(\n",
    "            npx_df,\n",
    "            max_downloads=MAX_DOWNLOADS,\n",
    "            output_dir=NPX_DOWNLOAD_DIR,\n",
    "            random_sample=True,  # Set to True to get a wide variety of N-PX\n",
    "            min_sleep=0.5,       # Wait at least 0.5s between requests\n",
    "            max_sleep=1.0        # Wait at most 1.0s between requests\n",
    "        )\n",
    "    else:\n",
    "        print(\"No N-PX data found for the specified year. No downloads performed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
