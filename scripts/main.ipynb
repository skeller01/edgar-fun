{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "# edgar_npx_downloader.ipynb CONTENT\n",
    "#####################################\n",
    "\n",
    "# 1. Imports and Globals\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Configuration\n",
    "TARGET_YEAR = 2024\n",
    "MAX_DOWNLOADS = 10  # can be set to None for all\n",
    "MASTER_INDEX_DIR = \"./edgar_index\"\n",
    "NPX_DOWNLOAD_DIR = \"./npx_filings\"\n",
    "#HEADERS = {\"User-Agent\": \"N-PX-Downloader (myemail@domain.com)\"}\n",
    "HEADERS = {\"User-Agent\": \"PythonRequests/3.0 (Generic Scraper)\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Download Master Index Function\n",
    "def download_master_index(year: int, quarter: int, base_dir: str = MASTER_INDEX_DIR) -> str:\n",
    "    \"\"\"\n",
    "    Downloads the master index for the specified year & quarter.\n",
    "    Saves it locally as {base_dir}/{year}_QTR{quarter}_master.idx.\n",
    "    Returns the local filepath.\n",
    "    \"\"\"\n",
    "    url = f\"https://www.sec.gov/Archives/edgar/full-index/{year}/QTR{quarter}/master.idx\"\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "    local_filename = os.path.join(base_dir, f\"{year}_QTR{quarter}_master.idx\")\n",
    "\n",
    "    print(f\"Downloading: {url}\")\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "    if response.status_code == 200:\n",
    "        with open(local_filename, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Saved to: {local_filename}\")\n",
    "        return local_filename\n",
    "    else:\n",
    "        print(f\"Failed to retrieve {url} [HTTP {response.status_code}].\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Parse Master Index\n",
    "def parse_master_index(idx_filepath: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parses a local .idx master index file and returns a DataFrame.\n",
    "    DataFrame columns: [cik, company_name, form_type, date_filed, filename].\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    if not os.path.exists(idx_filepath) or os.path.getsize(idx_filepath) == 0:\n",
    "        print(f\"Index file not found or empty: {idx_filepath}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    with open(idx_filepath, \"r\", encoding=\"latin-1\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Find the line with \"CIK|Company Name|Form Type|Date Filed|Filename\"\n",
    "    start_idx = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.strip().startswith(\"CIK|Company Name|Form Type|Date Filed|Filename\"):\n",
    "            start_idx = i + 1\n",
    "            break\n",
    "\n",
    "    if start_idx is None:\n",
    "        print(f\"Could not find the data header in: {idx_filepath}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Parse lines from start_idx onward\n",
    "    for line in lines[start_idx:]:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        parts = line.split(\"|\")\n",
    "        if len(parts) < 5:\n",
    "            continue\n",
    "        cik, company_name, form_type, date_filed, filename = parts[:5]\n",
    "        records.append({\n",
    "            \"cik\": cik,\n",
    "            \"company_name\": company_name,\n",
    "            \"form_type\": form_type,\n",
    "            \"date_filed\": date_filed,\n",
    "            \"filename\": filename\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Combine & Filter for N-PX\n",
    "def get_all_npx_for_year(year: int,\n",
    "                        base_dir: str = MASTER_INDEX_DIR,\n",
    "                        output_csv: str = \"npx_list.csv\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Downloads and parses the QTR1-QTR4 master indexes for the given year.\n",
    "    Filters for N-PX form types.\n",
    "    Saves combined results as a CSV: {base_dir}/{output_csv}.\n",
    "    Returns the N-PX DataFrame.\n",
    "    \"\"\"\n",
    "    combined_df = pd.DataFrame()\n",
    "\n",
    "    for quarter in [1, 2, 3, 4]:\n",
    "        idx_path = download_master_index(year, quarter, base_dir=base_dir)\n",
    "        if not idx_path:\n",
    "            # No file or failed download\n",
    "            continue\n",
    "        df_q = parse_master_index(idx_path)\n",
    "        if df_q.empty:\n",
    "            continue\n",
    "        combined_df = pd.concat([combined_df, df_q], ignore_index=True)\n",
    "\n",
    "    if combined_df.empty:\n",
    "        print(\"No data found for the entire year.\")\n",
    "        return combined_df\n",
    "\n",
    "    # Filter for N-PX only\n",
    "    mask_npx = combined_df[\"form_type\"].str.upper() == \"N-PX\"\n",
    "    npx_df = combined_df[mask_npx].copy()\n",
    "\n",
    "    # Save to CSV\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "    output_path = os.path.join(base_dir, output_csv)\n",
    "    npx_df.to_csv(output_path, index=False)\n",
    "    print(f\"Saved N-PX listings to {output_path}\")\n",
    "\n",
    "    return npx_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: https://www.sec.gov/Archives/edgar/full-index/2024/QTR1/master.idx\n",
      "Saved to: ./edgar_index\\2024_QTR1_master.idx\n",
      "Downloading: https://www.sec.gov/Archives/edgar/full-index/2024/QTR2/master.idx\n",
      "Saved to: ./edgar_index\\2024_QTR2_master.idx\n",
      "Downloading: https://www.sec.gov/Archives/edgar/full-index/2024/QTR3/master.idx\n",
      "Saved to: ./edgar_index\\2024_QTR3_master.idx\n",
      "Downloading: https://www.sec.gov/Archives/edgar/full-index/2024/QTR4/master.idx\n",
      "Saved to: ./edgar_index\\2024_QTR4_master.idx\n",
      "Saved N-PX listings to ./edgar_index\\npx_2024_list.csv\n"
     ]
    }
   ],
   "source": [
    "# 6. Aggregate N-PX for the Chosen Year\n",
    "npx_df = get_all_npx_for_year(\n",
    "    year=TARGET_YEAR,\n",
    "    base_dir=MASTER_INDEX_DIR,\n",
    "    output_csv=f\"npx_{TARGET_YEAR}_list.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Download N-PX Filings\n",
    "def download_npx_filings(npx_df: pd.DataFrame,\n",
    "                         max_downloads: int = 10,\n",
    "                         output_dir: str = NPX_DOWNLOAD_DIR):\n",
    "    \"\"\"\n",
    "    Download up to 'max_downloads' N-PX filings from the npx_df.\n",
    "    Saves them to 'output_dir'.\n",
    "    \"\"\"\n",
    "    if npx_df.empty:\n",
    "        print(\"No N-PX filings in the DataFrame.\")\n",
    "        return\n",
    "\n",
    "    if max_downloads is None:\n",
    "        max_downloads = len(npx_df)\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    subset_df = npx_df.head(max_downloads)\n",
    "\n",
    "    count = 0\n",
    "    for idx, row in subset_df.iterrows():\n",
    "        filename = row[\"filename\"].strip()\n",
    "        form_type = row[\"form_type\"].strip()\n",
    "        date_filed = row[\"date_filed\"].strip()\n",
    "\n",
    "        full_url = f\"https://www.sec.gov/Archives/{filename}\"\n",
    "        local_name = f\"{date_filed}_{form_type}_{os.path.basename(filename)}\"\n",
    "        local_path = os.path.join(output_dir, local_name)\n",
    "\n",
    "        print(f\"\\n[{count+1}/{max_downloads}] Downloading: {full_url}\")\n",
    "        try:\n",
    "            r = requests.get(full_url, headers=HEADERS)\n",
    "            if r.status_code == 200:\n",
    "                with open(local_path, \"wb\") as f:\n",
    "                    f.write(r.content)\n",
    "                print(f\"Saved to: {local_path}\")\n",
    "            else:\n",
    "                print(f\"Failed to download [HTTP {r.status_code}].\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading {full_url}: {e}\")\n",
    "\n",
    "        count += 1\n",
    "        # Sleep 0.2s for ~5 requests/sec\n",
    "        time.sleep(0.2)\n",
    "\n",
    "    print(f\"\\nCompleted. Downloaded {count} files.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/10] Downloading: https://www.sec.gov/Archives/edgar/data/1141819/0000894189-24-000782.txt\n",
      "Saved to: ./npx_filings\\2024-01-31_N-PX_0000894189-24-000782.txt\n",
      "\n",
      "[2/10] Downloading: https://www.sec.gov/Archives/edgar/data/1318342/0001398344-24-005683.txt\n",
      "Saved to: ./npx_filings\\2024-03-08_N-PX_0001398344-24-005683.txt\n",
      "\n",
      "[3/10] Downloading: https://www.sec.gov/Archives/edgar/data/1644419/0001398344-24-005976.txt\n",
      "Saved to: ./npx_filings\\2024-03-14_N-PX_0001398344-24-005976.txt\n",
      "\n",
      "[4/10] Downloading: https://www.sec.gov/Archives/edgar/data/1644419/0001580642-24-001712.txt\n",
      "Saved to: ./npx_filings\\2024-03-14_N-PX_0001580642-24-001712.txt\n",
      "\n",
      "[5/10] Downloading: https://www.sec.gov/Archives/edgar/data/1318342/0001398344-24-007059.txt\n",
      "Saved to: ./npx_filings\\2024-04-11_N-PX_0001398344-24-007059.txt\n",
      "\n",
      "[6/10] Downloading: https://www.sec.gov/Archives/edgar/data/1318342/0001398344-24-009755.txt\n",
      "Saved to: ./npx_filings\\2024-05-16_N-PX_0001398344-24-009755.txt\n",
      "\n",
      "[7/10] Downloading: https://www.sec.gov/Archives/edgar/data/1318342/0001398344-24-011810.txt\n",
      "Saved to: ./npx_filings\\2024-06-20_N-PX_0001398344-24-011810.txt\n",
      "\n",
      "[8/10] Downloading: https://www.sec.gov/Archives/edgar/data/1318342/0001398344-24-011954.txt\n",
      "Saved to: ./npx_filings\\2024-06-26_N-PX_0001398344-24-011954.txt\n",
      "\n",
      "[9/10] Downloading: https://www.sec.gov/Archives/edgar/data/1388485/0001829126-24-004328.txt\n",
      "Saved to: ./npx_filings\\2024-06-20_N-PX_0001829126-24-004328.txt\n",
      "\n",
      "[10/10] Downloading: https://www.sec.gov/Archives/edgar/data/1587982/0001398344-24-009075.txt\n",
      "Saved to: ./npx_filings\\2024-05-09_N-PX_0001398344-24-009075.txt\n",
      "\n",
      "Completed. Downloaded 10 files.\n"
     ]
    }
   ],
   "source": [
    "# 8. Execute the Download Step\n",
    "if not npx_df.empty:\n",
    "    download_npx_filings(\n",
    "        npx_df,\n",
    "        max_downloads=MAX_DOWNLOADS,\n",
    "        output_dir=NPX_DOWNLOAD_DIR\n",
    "    )\n",
    "else:\n",
    "    print(\"No N-PX data found for the specified year.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
