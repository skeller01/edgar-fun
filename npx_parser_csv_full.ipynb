{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3399970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import lxml.etree as ET\n",
    "\n",
    "# -----------------------------------------------------------------------\n",
    "# Global Data Lists (matching the final schema)\n",
    "# -----------------------------------------------------------------------\n",
    "FORM_NPX_ROWS = []\n",
    "INSTITUTIONAL_MANAGER_ROWS = []\n",
    "SERIES_ROWS = []\n",
    "PROXY_VOTING_RECORD_ROWS = []\n",
    "MATTER_CATEGORY_ROWS = []\n",
    "PROXY_VOTING_RECORD_CATEGORY_ROWS = []\n",
    "VOTING_RECORD_MANAGER_ROWS = []\n",
    "VOTING_RECORD_SERIES_ROWS = []\n",
    "\n",
    "# Weâ€™ll keep track of known categories (category_type -> category_id)\n",
    "KNOWN_CATEGORIES = {}\n",
    "\n",
    "# We'll generate incremental IDs for each form and each vote record\n",
    "NEXT_FORM_ID = 1\n",
    "NEXT_VOTE_ID = 1\n",
    "\n",
    "# -----------------------------------------------------------------------\n",
    "# Helper Functions\n",
    "# -----------------------------------------------------------------------\n",
    "\n",
    "def parse_date(date_string):\n",
    "    \"\"\"\n",
    "    Try to parse a date string in multiple formats, returning a Python date or None.\n",
    "    \"\"\"\n",
    "    if not date_string:\n",
    "        return None\n",
    "    patterns = [\"%m/%d/%Y\", \"%Y-%m-%d\", \"%m-%d-%Y\", \"%Y%m%d\"]\n",
    "    for fmt in patterns:\n",
    "        try:\n",
    "            return datetime.datetime.strptime(date_string.strip(), fmt).date()\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "def get_text(node, xpath_expr):\n",
    "    \"\"\"\n",
    "    Returns the .text of the first match or '' if none.\n",
    "    \"\"\"\n",
    "    result = node.xpath(xpath_expr)\n",
    "    if result and result[0] is not None and result[0].text:\n",
    "        return result[0].text.strip()\n",
    "    return \"\"\n",
    "\n",
    "def get_decimal(node, xpath_expr):\n",
    "    \"\"\"\n",
    "    Convert matched element text to float, ignoring commas. Return None if invalid.\n",
    "    \"\"\"\n",
    "    txt = get_text(node, xpath_expr)\n",
    "    if not txt:\n",
    "        return None\n",
    "    try:\n",
    "        return float(txt.replace(\",\", \"\"))\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def extract_sec_header_info(file_path):\n",
    "    \"\"\"\n",
    "    Parse <SEC-HEADER> lines: \"ACCESSION NUMBER:\" and \"FILED AS OF DATE:\" with regex.\n",
    "    Returns a dict with 'accession_number' (str) and 'date_filed' (date).\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "        raw = f.read()\n",
    "\n",
    "    info = {\n",
    "        \"accession_number\": \"\",\n",
    "        \"date_filed\": None\n",
    "    }\n",
    "\n",
    "    # Accession\n",
    "    match_acc = re.search(r\"ACCESSION\\s+NUMBER:\\s*([^\\r\\n]+)\", raw, re.IGNORECASE)\n",
    "    if match_acc:\n",
    "        info[\"accession_number\"] = match_acc.group(1).strip()\n",
    "\n",
    "    # FILED AS OF DATE\n",
    "    match_filed = re.search(r\"FILED\\s+AS\\s+OF\\s+DATE:\\s*(\\d{8})\", raw, re.IGNORECASE)\n",
    "    if match_filed:\n",
    "        info[\"date_filed\"] = parse_date(match_filed.group(1).strip())\n",
    "\n",
    "    return info\n",
    "\n",
    "def parse_edgar_submission(root, sec_header):\n",
    "    \"\"\"\n",
    "    Extract top-level data from <edgarSubmission> for the 'form_npx' table\n",
    "    (matching the final schema exactly).\n",
    "    \"\"\"\n",
    "    global NEXT_FORM_ID\n",
    "\n",
    "    form_id = NEXT_FORM_ID\n",
    "    NEXT_FORM_ID += 1\n",
    "\n",
    "    # Ensure no None for 'reporting_person_name' (NOT NULL in DB)\n",
    "    rp_name = get_text(root, \".//*[local-name()='reportingPerson']/*[local-name()='name']\")\n",
    "    if not rp_name:\n",
    "        rp_name = \"\"  # empty string instead of None\n",
    "\n",
    "    data = {\n",
    "        \"form_id\": form_id,\n",
    "\n",
    "        # Reporting Person / Filer Info\n",
    "        \"reporting_person_name\": rp_name[:250],  # NOT NULL => empty if unknown\n",
    "        \"phone_number\": get_text(root, \".//*[local-name()='reportingPerson']/*[local-name()='phoneNumber']\")[:50],\n",
    "        \"address_street1\": get_text(root, \".//*[local-name()='reportingPerson']/*[local-name()='address']/*[local-name()='street1']\")[:250],\n",
    "        \"address_street2\": get_text(root, \".//*[local-name()='reportingPerson']/*[local-name()='address']/*[local-name()='street2']\")[:250],\n",
    "        \"address_city\": get_text(root, \".//*[local-name()='reportingPerson']/*[local-name()='address']/*[local-name()='city']\")[:100],\n",
    "        \"address_state\": \"\",  # We'll set below if found\n",
    "        \"address_zip\": get_text(root, \".//*[local-name()='reportingPerson']/*[local-name()='address']/*[local-name()='zipCode']\")[:30],\n",
    "\n",
    "        # Form N-PX Filing Info\n",
    "        \"accession_number\": sec_header[\"accession_number\"][:30],\n",
    "        \"cik\": get_text(root, \".//*[local-name()='issuerCredentials']/*[local-name()='cik']\")[:15],\n",
    "        \"conformed_period\": parse_date(get_text(root, \".//*[local-name()='periodOfReport']\")),\n",
    "        \"date_filed\": sec_header[\"date_filed\"],\n",
    "        \"report_type\": (get_text(root, \".//*[local-name()='reportInfo']/*[local-name()='reportType']\") or \"FUND VOTING REPORT\")[:100],\n",
    "        \"form_type\": (get_text(root, \".//*[local-name()='submissionType']\") or \"N-PX\")[:10],\n",
    "        \"sec_file_number\": get_text(root, \".//*[local-name()='fileNumber']\")[:20],\n",
    "        \"crd_number\": get_text(root, \".//*[local-name()='reportingCrdNumber']\")[:20],\n",
    "        \"sec_file_number_other\": get_text(root, \".//*[local-name()='reportingSecFileNumber']\")[:20],\n",
    "        \"lei_number\": get_text(root, \".//*[local-name()='leiNumber']\")[:40],\n",
    "        \"investment_company_type\": get_text(root, \".//*[local-name()='investmentCompanyType']\")[:20],\n",
    "\n",
    "        # Must be 'Y' or 'N'\n",
    "        \"confidential_treatment\": \"N\",\n",
    "\n",
    "        # Boolean defaults\n",
    "        \"is_notice_report\": False,\n",
    "        \"explanatory_choice\": \"N\",\n",
    "        \"other_included_managers_count\": 0,\n",
    "        \"series_count\": 0,\n",
    "\n",
    "        # Amendment fields\n",
    "        \"is_amendment\": False,\n",
    "        \"amendment_no\": None,\n",
    "        \"amendment_type\": None,\n",
    "        \"notice_explanation\": None,  # up to 200 chars\n",
    "\n",
    "        # Signature fields\n",
    "        \"signatory_name\": get_text(root, \".//*[local-name()='signaturePage']/*[local-name()='txSignature']\")[:250],\n",
    "        \"signatory_name_printed\": get_text(root, \".//*[local-name()='signaturePage']/*[local-name()='txPrintedSignature']\")[:250],\n",
    "        \"signatory_title\": get_text(root, \".//*[local-name()='signaturePage']/*[local-name()='txTitle']\")[:100],\n",
    "        \"signatory_date\": parse_date(get_text(root, \".//*[local-name()='signaturePage']/*[local-name()='txAsOfDate']\")),\n",
    "    }\n",
    "\n",
    "    # If there's a stateOrCountry field, store it\n",
    "    raw_state_country = get_text(root, \".//*[local-name()='reportingPerson']/*[local-name()='address']/*[local-name()='stateOrCountry']\")\n",
    "    if raw_state_country:\n",
    "        data[\"address_state\"] = raw_state_country[:100]\n",
    "\n",
    "    # Check confidentialTreatment\n",
    "    conf_treat = get_text(root, \".//*[local-name()='reportInfo']/*[local-name()='confidentialTreatment']\").upper()\n",
    "    if conf_treat in [\"Y\", \"YES\", \"TRUE\", \"1\"]:\n",
    "        data[\"confidential_treatment\"] = \"Y\"\n",
    "\n",
    "    # Check if the report_type indicates a NOTICE report\n",
    "    if \"NOTICE\" in data[\"report_type\"].upper():\n",
    "        data[\"is_notice_report\"] = True\n",
    "\n",
    "    # Check explanatory_choice\n",
    "    expl_choice = get_text(root, \".//*[local-name()='explanatoryInformation']/*[local-name()='explanatoryChoice']\").upper()\n",
    "    if expl_choice in [\"Y\", \"YES\", \"TRUE\", \"1\"]:\n",
    "        data[\"explanatory_choice\"] = \"Y\"\n",
    "\n",
    "    # If we have an explanatoryNotes field, treat it as \"notice_explanation\" (max 200 chars)\n",
    "    #expl_notes = get_text(root, \".//*[local-name()='explanatoryInformation']/*[local-name()='explanatoryNotes']\")\n",
    "    #if expl_notes:\n",
    "    #    data[\"notice_explanation\"] = expl_notes[:200]\n",
    "\n",
    "    # If we have an explanatoryNotes field, treat it as \"notice_explanation\" (max 200 chars)\n",
    "    note_expl = get_text(root, \".//*[local-name()='reportInfo']/*[local-name()='noticeExplanation']\")\n",
    "    if note_expl:\n",
    "        data[\"notice_explanation\"] = note_expl[:200]\n",
    "\n",
    "    # otherIncludedManagersCount\n",
    "    oimc = get_text(root, \".//*[local-name()='summaryPage']/*[local-name()='otherIncludedManagersCount']\")\n",
    "    if oimc.isdigit():\n",
    "        data[\"other_included_managers_count\"] = int(oimc)\n",
    "\n",
    "    # isAmendment\n",
    "    is_amd = get_text(root, \".//*[local-name()='amendmentInfo']/*[local-name()='isAmendment']\").upper()\n",
    "    if is_amd in [\"Y\", \"YES\", \"TRUE\", \"1\"]:\n",
    "        data[\"is_amendment\"] = True\n",
    "\n",
    "    # amendment_no\n",
    "    amd_no = get_text(root, \".//*[local-name()='amendmentInfo']/*[local-name()='amendmentNo']\")\n",
    "    if amd_no.isdigit():\n",
    "        data[\"amendment_no\"] = int(amd_no)\n",
    "\n",
    "    # amendment_type\n",
    "    amd_type = get_text(root, \".//*[local-name()='amendmentInfo']/*[local-name()='amendmentType']\")\n",
    "    if amd_type:\n",
    "        data[\"amendment_type\"] = amd_type[:20]\n",
    "\n",
    "    return data\n",
    "\n",
    "def parse_institutional_managers(root, form_id):\n",
    "    \"\"\"\n",
    "    Extract institutional managers from <summaryPage> -> <otherManagers2> or <otherManager>.\n",
    "    Return a list of dicts for the 'institutional_manager' table.\n",
    "    \n",
    "    Now also checks for the official EDGAR tags:\n",
    "      - <managerName> (up to 150 chars)\n",
    "      - <icaOr13FFileNumber> (up to 17)\n",
    "      - <otherFileNumber> (up to 17)\n",
    "      - <leiNumberOM> (up to 20)\n",
    "      - <crdNumber> (up to 9 by the official spec, but we store up to 20)\n",
    "    Fallback logic:\n",
    "      - If <managerName> is found, use it, else fallback to <name>.\n",
    "      - If <icaOr13FFileNumber> is found, use it, else fallback to <form13FFileNumber>.\n",
    "      - If <otherFileNumber> is found, use it, else fallback to <secFileNumber>.\n",
    "      - If <leiNumberOM> is found, use it, else fallback to <leiNumber>.\n",
    "      - <crdNumber> is extracted from either tag if present\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    # Try <otherManagers2> -> <investmentManagers>, else <otherManager>\n",
    "    manager_nodes = root.xpath(\".//*[local-name()='otherManagers2']//*[local-name()='investmentManagers']\")\n",
    "    if not manager_nodes:\n",
    "        manager_nodes = root.xpath(\".//*[local-name()='otherManager']\")\n",
    "\n",
    "    for mn in manager_nodes:\n",
    "        row_im = {\n",
    "            \"manager_id\": None,   # Will assign in write_to_csv\n",
    "            \"form_id\": form_id,\n",
    "            \"serial_no\": None,    # int\n",
    "            \"name\": \"\",           # up to 250\n",
    "            \"form13f_number\": \"\", # up to 20\n",
    "            \"crd_number\": \"\",     # up to 20\n",
    "            \"sec_file_number\": \"\",# up to 20\n",
    "            \"lei_number\": \"\"      # up to 40\n",
    "        }\n",
    "\n",
    "        # 1) Serial No\n",
    "        sn = mn.xpath(\".//*[local-name()='serialNo']/text()\")\n",
    "        if sn and sn[0].isdigit():\n",
    "            row_im[\"serial_no\"] = int(sn[0])\n",
    "\n",
    "        # 2) Manager Name\n",
    "        #    official tag: <managerName> (up to 150)\n",
    "        #    fallback:    <name>\n",
    "        mgrName = mn.xpath(\".//*[local-name()='managerName']/text()\")\n",
    "        if mgrName:\n",
    "            row_im[\"name\"] = mgrName[0].strip()[:150]\n",
    "        else:\n",
    "            nm = mn.xpath(\".//*[local-name()='name']/text()\")\n",
    "            if nm:\n",
    "                row_im[\"name\"] = nm[0].strip()[:250]\n",
    "\n",
    "        # 3) 13F / ICA number\n",
    "        #    official: <icaOr13FFileNumber> up to 17\n",
    "        #    fallback: <form13FFileNumber> up to 20\n",
    "        ica = mn.xpath(\".//*[local-name()='icaOr13FFileNumber']/text()\")\n",
    "        if ica:\n",
    "            row_im[\"form13f_number\"] = ica[0].strip()[:17]\n",
    "        else:\n",
    "            f13 = mn.xpath(\".//*[local-name()='form13FFileNumber']/text()\")\n",
    "            if f13:\n",
    "                row_im[\"form13f_number\"] = f13[0].strip()[:20]\n",
    "\n",
    "        # 4) CRD number\n",
    "        #    official: <crdNumber> (up to 9), fallback is the same tag name\n",
    "        crdN = mn.xpath(\".//*[local-name()='crdNumber']/text()\")\n",
    "        if crdN:\n",
    "            # store up to 9 or 20 as the schema says 20\n",
    "            row_im[\"crd_number\"] = crdN[0].strip()[:20]\n",
    "\n",
    "        # 5) otherFileNumber or secFileNumber\n",
    "        #    official: <otherFileNumber> up to 17\n",
    "        #    fallback: <secFileNumber>\n",
    "        otherF = mn.xpath(\".//*[local-name()='otherFileNumber']/text()\")\n",
    "        if otherF:\n",
    "            row_im[\"sec_file_number\"] = otherF[0].strip()[:17]\n",
    "        else:\n",
    "            sfn = mn.xpath(\".//*[local-name()='secFileNumber']/text()\")\n",
    "            if sfn:\n",
    "                row_im[\"sec_file_number\"] = sfn[0].strip()[:20]\n",
    "\n",
    "        # 6) LEI number\n",
    "        #    official: <leiNumberOM> up to 20\n",
    "        #    fallback: <leiNumber> up to 40\n",
    "        leiOM = mn.xpath(\".//*[local-name()='leiNumberOM']/text()\")\n",
    "        if leiOM:\n",
    "            row_im[\"lei_number\"] = leiOM[0].strip()[:20]\n",
    "        else:\n",
    "            lei = mn.xpath(\".//*[local-name()='leiNumber']/text()\")\n",
    "            if lei:\n",
    "                row_im[\"lei_number\"] = lei[0].strip()[:40]\n",
    "\n",
    "        results.append(row_im)\n",
    "\n",
    "    return results\n",
    "\n",
    "def parse_series_info(root, form_dict):\n",
    "    \"\"\"\n",
    "    <seriesPage> -> <seriesDetails> -> <seriesReports>\n",
    "    Returns a list referencing form_id for the 'series' table.\n",
    "    Also updates 'series_count' in the form_npx row.\n",
    "    \"\"\"\n",
    "    form_id = form_dict[\"form_id\"]\n",
    "    series_nodes = root.xpath(\".//*[local-name()='seriesReports']\")\n",
    "    results = []\n",
    "    for sn in series_nodes:\n",
    "        s_data = {\n",
    "            \"series_id\": None,\n",
    "            \"form_id\": form_id,\n",
    "            \"series_code\": get_text(sn, \".//*[local-name()='idOfSeries']\")[:25],\n",
    "            \"series_name\": get_text(sn, \".//*[local-name()='nameOfSeries']\")[:250],\n",
    "            \"series_lei\": get_text(sn, \".//*[local-name()='leiOfSeries']\")[:40],\n",
    "        }\n",
    "        results.append(s_data)\n",
    "\n",
    "    form_dict[\"series_count\"] += len(results)\n",
    "    return results\n",
    "\n",
    "def parse_proxy_vote_table(proxy_vote_node, form_id):\n",
    "    \"\"\"\n",
    "    Parse each <proxyTable> inside <proxyVoteTable> => rows for 'proxy_voting_record'\n",
    "    plus bridging rows for managers & series.\n",
    "    \"\"\"\n",
    "    global NEXT_VOTE_ID\n",
    "\n",
    "    for pt in proxy_vote_node.xpath(\".//*[local-name()='proxyTable']\"):\n",
    "        vote_id = NEXT_VOTE_ID\n",
    "        NEXT_VOTE_ID += 1\n",
    "\n",
    "        row = {\n",
    "            \"vote_id\": vote_id,\n",
    "            \"form_id\": form_id,\n",
    "            \"issuer_name\": get_text(pt, \".//*[local-name()='issuerName']\")[:250],\n",
    "            \"cusip\": get_text(pt, \".//*[local-name()='cusip']\")[:30],\n",
    "            \"isin\": get_text(pt, \".//*[local-name()='isin']\")[:30],\n",
    "            \"figi\": get_text(pt, \".//*[local-name()='figi']\")[:30],\n",
    "            \"meeting_date\": parse_date(get_text(pt, \".//*[local-name()='meetingDate']\")),\n",
    "            \"vote_description\": get_text(pt, \".//*[local-name()='voteDescription']\"),  # TEXT\n",
    "            \"proposed_by\": get_text(pt, \".//*[local-name()='voteSource']\")[:20],\n",
    "            \"shares_voted\": get_decimal(pt, \".//*[local-name()='sharesVoted'][1]\"),     # numeric(20,6)\n",
    "            \"shares_on_loan\": get_decimal(pt, \".//*[local-name()='sharesOnLoan'][1]\"),  # numeric(20,6)\n",
    "            \"vote_cast\": None,            # varchar(50)\n",
    "            \"vote_cast_shares\": None,     # numeric(20,6)\n",
    "            \"management_rec\": None,       # varchar(50)\n",
    "            \"other_notes\": None           # text\n",
    "        }\n",
    "\n",
    "        vote_records = pt.xpath(\".//*[local-name()='voteRecord']\")\n",
    "        if vote_records:\n",
    "            vr = vote_records[0]\n",
    "            row[\"vote_cast\"] = get_text(vr, \".//*[local-name()='howVoted']\")[:50]\n",
    "            row[\"vote_cast_shares\"] = get_decimal(vr, \".//*[local-name()='sharesVoted']\")\n",
    "            row[\"management_rec\"] = get_text(vr, \".//*[local-name()='managementRecommendation']\")[:50]\n",
    "\n",
    "            if len(vote_records) > 1:\n",
    "                row[\"other_notes\"] = f\"{len(vote_records)} total <voteRecord> items found.\"\n",
    "\n",
    "        PROXY_VOTING_RECORD_ROWS.append(row)\n",
    "\n",
    "        # Parse categories (<voteCategories>)\n",
    "        categories = pt.xpath(\".//*[local-name()='voteCategories']//*[local-name()='categoryType']/text()\")\n",
    "        for cat_str in categories:\n",
    "            cat_clean = cat_str.strip()[:100]\n",
    "            if cat_clean not in KNOWN_CATEGORIES:\n",
    "                new_cat_id = len(KNOWN_CATEGORIES) + 1\n",
    "                KNOWN_CATEGORIES[cat_clean] = new_cat_id\n",
    "                MATTER_CATEGORY_ROWS.append({\"category_id\": new_cat_id, \"category_type\": cat_clean})\n",
    "\n",
    "            cat_id = KNOWN_CATEGORIES[cat_clean]\n",
    "            PROXY_VOTING_RECORD_CATEGORY_ROWS.append({\n",
    "                \"vote_id\": vote_id,\n",
    "                \"category_id\": cat_id\n",
    "            })\n",
    "\n",
    "        # Parse manager references: store (form_id, serial_no) placeholders\n",
    "        other_mgrs = pt.xpath(\".//*[local-name()='voteManager']//*[local-name()='otherManager']/text()\")\n",
    "        for mgr_code in other_mgrs:\n",
    "            mgr_code = mgr_code.strip()\n",
    "            try:\n",
    "                serial_no_int = int(mgr_code)\n",
    "            except ValueError:\n",
    "                serial_no_int = None\n",
    "\n",
    "            if serial_no_int is not None:\n",
    "                VOTING_RECORD_MANAGER_ROWS.append({\n",
    "                    \"vote_id\": vote_id,\n",
    "                    \"manager_id\": None,  # unify later\n",
    "                    \"form_id\": form_id,\n",
    "                    \"serial_no\": serial_no_int\n",
    "                })\n",
    "\n",
    "        # Parse series reference (<voteSeries>)\n",
    "        vs_code = get_text(pt, \".//*[local-name()='voteSeries']\")\n",
    "        if vs_code:\n",
    "            vs_code = vs_code.strip()[:25]\n",
    "            VOTING_RECORD_SERIES_ROWS.append({\n",
    "                \"vote_id\": vote_id,\n",
    "                \"series_id\": None,  # unify later\n",
    "                \"form_id\": form_id,\n",
    "                \"series_code\": vs_code\n",
    "            })\n",
    "\n",
    "def extract_xml_blocks(file_path):\n",
    "    \"\"\"\n",
    "    Return a list of <XML> ... </XML> substrings from the file.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "        text = f.read()\n",
    "    pattern = re.compile(r\"<XML>(.*?)</XML>\", re.IGNORECASE | re.DOTALL)\n",
    "    return pattern.findall(text)\n",
    "\n",
    "def parse_xml_fragment(xml_string):\n",
    "    \"\"\"\n",
    "    Attempt to parse an XML fragment with lxml.etree in recovery mode.\n",
    "    \"\"\"\n",
    "    parser = ET.XMLParser(recover=True, encoding=\"utf-8\")\n",
    "    try:\n",
    "        root = ET.fromstring(xml_string.encode(\"utf-8\"), parser=parser)\n",
    "        return root\n",
    "    except ET.XMLSyntaxError as e:\n",
    "        print(f\"  [Warning] parse error: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_npx_files(folder_path=\"npx_filings\"):\n",
    "    \"\"\"\n",
    "    Main loop over each .txt file. For each:\n",
    "      - read SEC header\n",
    "      - find <XML> blocks\n",
    "      - parse <edgarSubmission>\n",
    "      - parse institutional managers & series\n",
    "      - parse <proxyVoteTable>\n",
    "    \"\"\"\n",
    "    global NEXT_FORM_ID\n",
    "    global FORM_NPX_ROWS, INSTITUTIONAL_MANAGER_ROWS, SERIES_ROWS\n",
    "\n",
    "    all_files = os.listdir(folder_path)\n",
    "    txt_files = [f for f in all_files if f.lower().endswith(\".txt\")]\n",
    "\n",
    "    for fname in txt_files:\n",
    "        file_path = os.path.join(folder_path, fname)\n",
    "        print(f\"\\nProcessing: {file_path}\")\n",
    "\n",
    "        header_info = extract_sec_header_info(file_path)\n",
    "        xml_fragments = extract_xml_blocks(file_path)\n",
    "        if not xml_fragments:\n",
    "            print(\"  No <XML> blocks found.\")\n",
    "            continue\n",
    "\n",
    "        found_form_data = False\n",
    "        current_form = None\n",
    "\n",
    "        for frag in xml_fragments:\n",
    "            root = parse_xml_fragment(frag)\n",
    "            if root is None:\n",
    "                continue\n",
    "\n",
    "            es_nodes = root.xpath(\"//*[local-name()='edgarSubmission']\")\n",
    "            if es_nodes:\n",
    "                es = es_nodes[0]\n",
    "                form_row = parse_edgar_submission(es, header_info)\n",
    "                current_form = form_row\n",
    "                FORM_NPX_ROWS.append(form_row)\n",
    "                found_form_data = True\n",
    "\n",
    "                im_list = parse_institutional_managers(es, form_row[\"form_id\"])\n",
    "                INSTITUTIONAL_MANAGER_ROWS.extend(im_list)\n",
    "\n",
    "                s_list = parse_series_info(es, form_row)\n",
    "                SERIES_ROWS.extend(s_list)\n",
    "\n",
    "            pvt_nodes = root.xpath(\"//*[local-name()='proxyVoteTable']\")\n",
    "            if pvt_nodes:\n",
    "                if not found_form_data:\n",
    "                    # Minimal form if there's a <proxyVoteTable> but no <edgarSubmission>\n",
    "                    form_id = NEXT_FORM_ID\n",
    "                    NEXT_FORM_ID += 1\n",
    "                    minimal_form = {\n",
    "                        \"form_id\": form_id,\n",
    "                        \"reporting_person_name\": \"\",  # NOT NULL => empty if unknown\n",
    "                        \"phone_number\": \"\",\n",
    "                        \"address_street1\": \"\",\n",
    "                        \"address_street2\": \"\",\n",
    "                        \"address_city\": \"\",\n",
    "                        \"address_state\": \"\",\n",
    "                        \"address_zip\": \"\",\n",
    "                        \"accession_number\": header_info[\"accession_number\"][:30],\n",
    "                        \"cik\": \"\",\n",
    "                        \"conformed_period\": None,\n",
    "                        \"date_filed\": header_info[\"date_filed\"],\n",
    "                        \"report_type\": \"FUND VOTING REPORT\",\n",
    "                        \"form_type\": \"N-PX\",\n",
    "                        \"sec_file_number\": \"\",\n",
    "                        \"crd_number\": \"\",\n",
    "                        \"sec_file_number_other\": \"\",\n",
    "                        \"lei_number\": \"\",\n",
    "                        \"investment_company_type\": \"\",\n",
    "                        \"confidential_treatment\": \"N\",\n",
    "                        \"is_notice_report\": False,\n",
    "                        \"explanatory_choice\": \"N\",\n",
    "                        \"other_included_managers_count\": 0,\n",
    "                        \"series_count\": 0,\n",
    "                        \"is_amendment\": False,\n",
    "                        \"amendment_no\": None,\n",
    "                        \"amendment_type\": None,\n",
    "                        \"notice_explanation\": None,\n",
    "                        \"signatory_name\": \"\",\n",
    "                        \"signatory_name_printed\": \"\",\n",
    "                        \"signatory_title\": \"\",\n",
    "                        \"signatory_date\": None,\n",
    "                    }\n",
    "                    FORM_NPX_ROWS.append(minimal_form)\n",
    "                    current_form = minimal_form\n",
    "                    found_form_data = True\n",
    "\n",
    "                for pvt in pvt_nodes:\n",
    "                    parse_proxy_vote_table(pvt, current_form[\"form_id\"])\n",
    "\n",
    "    print(\"\\nFinished parsing N-PX.\")\n",
    "    print(f\"  Forms: {len(FORM_NPX_ROWS)}\")\n",
    "    print(f\"  Proxy Voting Rows: {len(PROXY_VOTING_RECORD_ROWS)}\")\n",
    "\n",
    "def unify_voting_references():\n",
    "    \"\"\"\n",
    "    Replace the placeholder (form_id, serial_no) or (form_id, series_code)\n",
    "    in VOTING_RECORD_MANAGER_ROWS / VOTING_RECORD_SERIES_ROWS \n",
    "    with the assigned manager_id or series_id.\n",
    "    \"\"\"\n",
    "    # 1) Build manager lookup\n",
    "    manager_lookup = {}\n",
    "    for im_row in INSTITUTIONAL_MANAGER_ROWS:\n",
    "        key = (im_row[\"form_id\"], im_row[\"serial_no\"])\n",
    "        manager_lookup[key] = im_row[\"manager_id\"]\n",
    "\n",
    "    for vrm in VOTING_RECORD_MANAGER_ROWS:\n",
    "        key = (vrm[\"form_id\"], vrm[\"serial_no\"])\n",
    "        vrm[\"manager_id\"] = manager_lookup.get(key, None)\n",
    "\n",
    "    # 2) Build series lookup\n",
    "    series_lookup = {}\n",
    "    for s_row in SERIES_ROWS:\n",
    "        key = (s_row[\"form_id\"], s_row[\"series_code\"])\n",
    "        series_lookup[key] = s_row[\"series_id\"]\n",
    "\n",
    "    for vrs in VOTING_RECORD_SERIES_ROWS:\n",
    "        key = (vrs[\"form_id\"], vrs[\"series_code\"])\n",
    "        vrs[\"series_id\"] = series_lookup.get(key, None)\n",
    "\n",
    "def write_to_csv(output_folder=\"output_csv\"):\n",
    "    \"\"\"\n",
    "    Writes each global list to CSV, ensuring columns match the schema.\n",
    "    Then calls unify_voting_references() so bridging tables get correct IDs.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # -----------------------------------------------------------------------\n",
    "    # form_npx\n",
    "    # -----------------------------------------------------------------------\n",
    "    df_form = pd.DataFrame(FORM_NPX_ROWS)\n",
    "    date_cols = [\"conformed_period\", \"date_filed\", \"signatory_date\"]\n",
    "    for dc in date_cols:\n",
    "        if dc in df_form.columns:\n",
    "            df_form[dc] = pd.to_datetime(df_form[dc], errors=\"coerce\").dt.date\n",
    "    df_form.drop_duplicates(subset=[\"form_id\"], inplace=True)\n",
    "\n",
    "    form_npx_columns = [\n",
    "        \"form_id\",\n",
    "        \"reporting_person_name\",\n",
    "        \"phone_number\",\n",
    "        \"address_street1\",\n",
    "        \"address_street2\",\n",
    "        \"address_city\",\n",
    "        \"address_state\",\n",
    "        \"address_zip\",\n",
    "        \"accession_number\",\n",
    "        \"cik\",\n",
    "        \"conformed_period\",\n",
    "        \"date_filed\",\n",
    "        \"report_type\",\n",
    "        \"form_type\",\n",
    "        \"sec_file_number\",\n",
    "        \"crd_number\",\n",
    "        \"sec_file_number_other\",\n",
    "        \"lei_number\",\n",
    "        \"investment_company_type\",\n",
    "        \"confidential_treatment\",\n",
    "        \"is_notice_report\",\n",
    "        \"explanatory_choice\",\n",
    "        \"other_included_managers_count\",\n",
    "        \"series_count\",\n",
    "        \"is_amendment\",\n",
    "        \"amendment_no\",\n",
    "        \"amendment_type\",\n",
    "        \"notice_explanation\",\n",
    "        \"signatory_name\",\n",
    "        \"signatory_name_printed\",\n",
    "        \"signatory_title\",\n",
    "        \"signatory_date\"\n",
    "    ]\n",
    "    for col in form_npx_columns:\n",
    "        if col not in df_form.columns:\n",
    "            df_form[col] = None\n",
    "    df_form = df_form[form_npx_columns]\n",
    "\n",
    "    csv_form = os.path.join(output_folder, \"form_npx.csv\")\n",
    "    df_form.to_csv(csv_form, index=False)\n",
    "    print(f\"Saved form_npx.csv: {len(df_form)} rows.\")\n",
    "\n",
    "    # -----------------------------------------------------------------------\n",
    "    # institutional_manager\n",
    "    # -----------------------------------------------------------------------\n",
    "    df_im = pd.DataFrame(INSTITUTIONAL_MANAGER_ROWS)\n",
    "    if not df_im.empty:\n",
    "        df_im.drop_duplicates(\n",
    "            subset=[\"form_id\",\"serial_no\",\"name\",\"form13f_number\",\"crd_number\",\"sec_file_number\",\"lei_number\"],\n",
    "            inplace=True\n",
    "        )\n",
    "        # assign new IDs\n",
    "        df_im[\"manager_id\"] = range(1, len(df_im) + 1)\n",
    "        # push them back\n",
    "        df_im_reset = df_im.reset_index(drop=True)\n",
    "        for i, row in df_im_reset.iterrows():\n",
    "            INSTITUTIONAL_MANAGER_ROWS[i][\"manager_id\"] = row[\"manager_id\"]\n",
    "\n",
    "    im_columns = [\n",
    "        \"manager_id\",\n",
    "        \"form_id\",\n",
    "        \"serial_no\",\n",
    "        \"name\",\n",
    "        \"form13f_number\",\n",
    "        \"crd_number\",\n",
    "        \"sec_file_number\",\n",
    "        \"lei_number\"\n",
    "    ]\n",
    "    for col in im_columns:\n",
    "        if col not in df_im.columns:\n",
    "            df_im[col] = None\n",
    "    df_im = df_im[im_columns]\n",
    "\n",
    "    csv_im = os.path.join(output_folder, \"institutional_manager.csv\")\n",
    "    df_im.to_csv(csv_im, index=False)\n",
    "    print(f\"Saved institutional_manager.csv: {len(df_im)} rows.\")\n",
    "\n",
    "    # -----------------------------------------------------------------------\n",
    "    # series\n",
    "    # -----------------------------------------------------------------------\n",
    "    df_s = pd.DataFrame(SERIES_ROWS)\n",
    "    if not df_s.empty:\n",
    "        df_s.drop_duplicates(\n",
    "            subset=[\"form_id\",\"series_code\",\"series_name\",\"series_lei\"],\n",
    "            inplace=True\n",
    "        )\n",
    "        df_s[\"series_id\"] = range(1, len(df_s) + 1)\n",
    "        df_s_reset = df_s.reset_index(drop=True)\n",
    "        for i, row in df_s_reset.iterrows():\n",
    "            SERIES_ROWS[i][\"series_id\"] = row[\"series_id\"]\n",
    "\n",
    "    s_columns = [\n",
    "        \"series_id\",\n",
    "        \"form_id\",\n",
    "        \"series_code\",\n",
    "        \"series_name\",\n",
    "        \"series_lei\"\n",
    "    ]\n",
    "    for col in s_columns:\n",
    "        if col not in df_s.columns:\n",
    "            df_s[col] = None\n",
    "    df_s = df_s[s_columns]\n",
    "\n",
    "    csv_s = os.path.join(output_folder, \"series.csv\")\n",
    "    df_s.to_csv(csv_s, index=False)\n",
    "    print(f\"Saved series.csv: {len(df_s)} rows.\")\n",
    "\n",
    "    # -----------------------------------------------------------------------\n",
    "    # unify bridging references (manager_id, series_id)\n",
    "    # -----------------------------------------------------------------------\n",
    "    unify_voting_references()\n",
    "\n",
    "    # -----------------------------------------------------------------------\n",
    "    # proxy_voting_record\n",
    "    # -----------------------------------------------------------------------\n",
    "    df_pvr = pd.DataFrame(PROXY_VOTING_RECORD_ROWS)\n",
    "    if not df_pvr.empty:\n",
    "        df_pvr.drop_duplicates(subset=[\"vote_id\"], inplace=True)\n",
    "        if \"meeting_date\" in df_pvr.columns:\n",
    "            df_pvr[\"meeting_date\"] = pd.to_datetime(df_pvr[\"meeting_date\"], errors=\"coerce\").dt.date\n",
    "\n",
    "    pvr_columns = [\n",
    "        \"vote_id\",\n",
    "        \"form_id\",\n",
    "        \"issuer_name\",\n",
    "        \"cusip\",\n",
    "        \"isin\",\n",
    "        \"figi\",\n",
    "        \"meeting_date\",\n",
    "        \"vote_description\",\n",
    "        \"proposed_by\",\n",
    "        \"shares_voted\",\n",
    "        \"shares_on_loan\",\n",
    "        \"vote_cast\",\n",
    "        \"vote_cast_shares\",\n",
    "        \"management_rec\",\n",
    "        \"other_notes\"\n",
    "    ]\n",
    "    for col in pvr_columns:\n",
    "        if col not in df_pvr.columns:\n",
    "            df_pvr[col] = None\n",
    "    df_pvr = df_pvr[pvr_columns]\n",
    "\n",
    "    csv_pvr = os.path.join(output_folder, \"proxy_voting_record.csv\")\n",
    "    df_pvr.to_csv(csv_pvr, index=False)\n",
    "    print(f\"Saved proxy_voting_record.csv: {len(df_pvr)} rows.\")\n",
    "\n",
    "    # -----------------------------------------------------------------------\n",
    "    # matter_category\n",
    "    # -----------------------------------------------------------------------\n",
    "    df_mc = pd.DataFrame(MATTER_CATEGORY_ROWS)\n",
    "    if not df_mc.empty:\n",
    "        df_mc.drop_duplicates(subset=[\"category_type\"], inplace=True)\n",
    "\n",
    "    mc_columns = [\"category_id\", \"category_type\"]\n",
    "    for col in mc_columns:\n",
    "        if col not in df_mc.columns:\n",
    "            df_mc[col] = None\n",
    "    df_mc = df_mc[mc_columns]\n",
    "\n",
    "    csv_mc = os.path.join(output_folder, \"matter_category.csv\")\n",
    "    df_mc.to_csv(csv_mc, index=False)\n",
    "    print(f\"Saved matter_category.csv: {len(df_mc)} rows.\")\n",
    "\n",
    "    # -----------------------------------------------------------------------\n",
    "    # proxy_voting_record_category\n",
    "    # -----------------------------------------------------------------------\n",
    "    df_pvrc = pd.DataFrame(PROXY_VOTING_RECORD_CATEGORY_ROWS)\n",
    "    if not df_pvrc.empty:\n",
    "        df_pvrc.drop_duplicates(inplace=True)\n",
    "\n",
    "    pvrc_columns = [\"vote_id\", \"category_id\"]\n",
    "    for col in pvrc_columns:\n",
    "        if col not in df_pvrc.columns:\n",
    "            df_pvrc[col] = None\n",
    "    df_pvrc = df_pvrc[pvrc_columns]\n",
    "\n",
    "    csv_pvrc = os.path.join(output_folder, \"proxy_voting_record_category.csv\")\n",
    "    df_pvrc.to_csv(csv_pvrc, index=False)\n",
    "    print(f\"Saved proxy_voting_record_category.csv: {len(df_pvrc)} rows.\")\n",
    "\n",
    "    # -----------------------------------------------------------------------\n",
    "    # voting_record_manager\n",
    "    # -----------------------------------------------------------------------\n",
    "    df_vrm = pd.DataFrame(VOTING_RECORD_MANAGER_ROWS)\n",
    "    if not df_vrm.empty:\n",
    "        df_vrm.drop_duplicates(inplace=True)\n",
    "\n",
    "    vrm_columns = [\"vote_id\", \"manager_id\"]\n",
    "    for col in vrm_columns:\n",
    "        if col not in df_vrm.columns:\n",
    "            df_vrm[col] = None\n",
    "    df_vrm = df_vrm[vrm_columns]\n",
    "\n",
    "    csv_vrm = os.path.join(output_folder, \"voting_record_manager.csv\")\n",
    "    df_vrm.to_csv(csv_vrm, index=False)\n",
    "    print(f\"Saved voting_record_manager.csv: {len(df_vrm)} rows.\")\n",
    "\n",
    "    # -----------------------------------------------------------------------\n",
    "    # voting_record_series\n",
    "    # -----------------------------------------------------------------------\n",
    "    df_vrs = pd.DataFrame(VOTING_RECORD_SERIES_ROWS)\n",
    "    if not df_vrs.empty:\n",
    "        df_vrs.drop_duplicates(inplace=True)\n",
    "\n",
    "    vrs_columns = [\"vote_id\", \"series_id\"]\n",
    "    for col in vrs_columns:\n",
    "        if col not in df_vrs.columns:\n",
    "            df_vrs[col] = None\n",
    "    df_vrs = df_vrs[vrs_columns]\n",
    "\n",
    "    csv_vrs = os.path.join(output_folder, \"voting_record_series.csv\")\n",
    "    df_vrs.to_csv(csv_vrs, index=False)\n",
    "    print(f\"Saved voting_record_series.csv: {len(df_vrs)} rows.\")\n",
    "\n",
    "    print(\"\\nAll CSVs have been written. Check your output folder to confirm.\")\n",
    "\n",
    "def run_all(folder_path=\"npx_filings\", output_folder=\"output_csv\"):\n",
    "    \"\"\"\n",
    "    High-level convenience function to:\n",
    "      1) Reset global data\n",
    "      2) Parse the N-PX .txt files\n",
    "      3) Write results to CSV\n",
    "    \"\"\"\n",
    "    global FORM_NPX_ROWS, INSTITUTIONAL_MANAGER_ROWS, SERIES_ROWS\n",
    "    global PROXY_VOTING_RECORD_ROWS, MATTER_CATEGORY_ROWS\n",
    "    global PROXY_VOTING_RECORD_CATEGORY_ROWS, VOTING_RECORD_MANAGER_ROWS\n",
    "    global VOTING_RECORD_SERIES_ROWS, KNOWN_CATEGORIES\n",
    "    global NEXT_FORM_ID, NEXT_VOTE_ID\n",
    "\n",
    "    # Reset everything\n",
    "    FORM_NPX_ROWS = []\n",
    "    INSTITUTIONAL_MANAGER_ROWS = []\n",
    "    SERIES_ROWS = []\n",
    "    PROXY_VOTING_RECORD_ROWS = []\n",
    "    MATTER_CATEGORY_ROWS = []\n",
    "    PROXY_VOTING_RECORD_CATEGORY_ROWS = []\n",
    "    VOTING_RECORD_MANAGER_ROWS = []\n",
    "    VOTING_RECORD_SERIES_ROWS = []\n",
    "    KNOWN_CATEGORIES = {}\n",
    "\n",
    "    NEXT_FORM_ID = 1\n",
    "    NEXT_VOTE_ID = 1\n",
    "\n",
    "    # Parse the files\n",
    "    process_npx_files(folder_path)\n",
    "\n",
    "    # Write the results to CSV\n",
    "    write_to_csv(output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "978e7b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: npx_filings\\2024-05-17_N-PX_A_0001193125-24-141098.txt\n",
      "  No <XML> blocks found.\n",
      "\n",
      "Processing: npx_filings\\2024-05-17_N-PX_A_0001193125-24-141099.txt\n",
      "  No <XML> blocks found.\n",
      "\n",
      "Processing: npx_filings\\2024-06-20_N-PX_0001829126-24-004328.txt\n",
      "  No <XML> blocks found.\n",
      "\n",
      "Processing: npx_filings\\2024-07-03_N-PX_0001896711-24-000005.txt\n",
      "\n",
      "Processing: npx_filings\\2024-07-09_N-PX_0001512026-24-000004.txt\n",
      "\n",
      "Processing: npx_filings\\2024-07-17_N-PX_0001140361-24-033397.txt\n",
      "\n",
      "Processing: npx_filings\\2024-07-22_N-PX_0001085146-24-003136.txt\n",
      "\n",
      "Processing: npx_filings\\2024-07-23_N-PX_0001754960-24-000314.txt\n",
      "\n",
      "Processing: npx_filings\\2024-07-24_N-PX_0001801413-24-000006.txt\n",
      "\n",
      "Processing: npx_filings\\2024-07-26_N-PX_0001172661-24-002922.txt\n",
      "\n",
      "Processing: npx_filings\\2024-07-30_N-PX_0001044929-24-000010.txt\n",
      "\n",
      "Processing: npx_filings\\2024-07-31_N-PX_0001667731-24-000356.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-02_N-PX_0001085146-24-003449.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-05_N-PX_0001413042-24-000583.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-05_N-PX_0001992316-24-000005.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-06_N-PX_0001420506-24-001272.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-06_N-PX_0001907802-24-000004.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-07_N-PX_0001213900-24-065984.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-09_N-PX_0001085146-24-003654.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-13_N-PX_0000938076-24-000010.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-16_N-PX_0001085146-24-004045.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-16_N-PX_0001438934-24-000297.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-19_N-PX_0001172661-24-003618.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-19_N-PX_0001214659-24-014902.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-19_N-PX_0001665751-24-000005.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-19_N-PX_0002009176-24-000005.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-20_N-PX_0001438934-24-000364.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-20_N-PX_0001588873-24-000007.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-21_N-PX_0001085146-24-004099.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-21_N-PX_0001162044-24-000889.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-21_N-PX_0001842669-24-000002.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-21_N-PX_0001951757-24-000843.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-21_N-PX_0001951757-24-000855.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-22_N-PX_0001081400-24-000470.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-22_N-PX_0001085146-24-004165.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-22_N-PX_0001172661-24-003655.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-22_N-PX_0001633903-24-000006.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-23_N-PX_0000088053-24-000800.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-27_N-PX_0001021408-24-004370.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-27_N-PX_0001021408-24-004835.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-27_N-PX_0001021408-24-004863.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-27_N-PX_0001021408-24-004897.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-27_N-PX_0001085146-24-004249.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-27_N-PX_0001085146-24-004261.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-27_N-PX_0001104659-24-093417.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-27_N-PX_0001172661-24-003724.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-27_N-PX_0001172661-24-003731.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-27_N-PX_0001172661-24-003732.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-27_N-PX_0001420506-24-001751.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-27_N-PX_0001754960-24-000450.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-27_N-PX_0001843578-24-000005.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-27_N-PX_0001909089-24-000007.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-27_N-PX_0002000324-24-002324.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-28_N-PX_0000922423-24-000058.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-28_N-PX_0001104659-24-093739.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-28_N-PX_0001104659-24-093869.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-28_N-PX_0001442181-24-000009.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-28_N-PX_0001623632-24-001412.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-28_N-PX_0001974403-24-000005.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-29_N-PX_0000930413-24-002583.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-29_N-PX_0000930413-24-002603.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-29_N-PX_0001021408-24-005566.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-29_N-PX_0001021408-24-005821.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-29_N-PX_0001085146-24-004334.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-29_N-PX_0001104659-24-094319.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-29_N-PX_0001104659-24-094442.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-29_N-PX_0001104659-24-094771.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-29_N-PX_0001104659-24-094827.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-29_N-PX_0001140361-24-039158.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-29_N-PX_0001172661-24-003824.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-29_N-PX_0001398344-24-016292.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-29_N-PX_0001420506-24-001885.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-29_N-PX_0001438934-24-001183.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-29_N-PX_0001633864-24-000005.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-29_N-PX_0001658020-24-000013.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-29_N-PX_0001695344-24-000002.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-29_N-PX_0001755028-24-000004.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-30_N-PX_0001085146-24-004496.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-30_N-PX_0001104659-24-095128.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-30_N-PX_0001104659-24-095163.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-30_N-PX_0001104659-24-095193.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-30_N-PX_0001140361-24-039741.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-30_N-PX_0001318025-24-000043.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-30_N-PX_0001398344-24-016969.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-30_N-PX_0001438934-24-001421.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-30_N-PX_0001438934-24-001636.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-30_N-PX_0001493152-24-034639.txt\n",
      "\n",
      "Processing: npx_filings\\2024-08-30_N-PX_0001839882-24-027753.txt\n",
      "\n",
      "Processing: npx_filings\\2024-09-03_N-PX_0001021408-24-007106.txt\n",
      "\n",
      "Processing: npx_filings\\2024-09-03_N-PX_0001021408-24-007127.txt\n",
      "\n",
      "Processing: npx_filings\\2024-09-03_N-PX_0001021408-24-007140.txt\n",
      "\n",
      "Processing: npx_filings\\2024-09-03_N-PX_0001104659-24-095761.txt\n",
      "\n",
      "Processing: npx_filings\\2024-09-03_N-PX_0001104659-24-096213.txt\n",
      "\n",
      "Processing: npx_filings\\2024-09-03_N-PX_0001563660-24-000089.txt\n",
      "\n",
      "Processing: npx_filings\\2024-09-03_N-PX_0002000324-24-002636.txt\n",
      "\n",
      "Processing: npx_filings\\2024-09-03_N-PX_0002000324-24-002697.txt\n",
      "\n",
      "Processing: npx_filings\\2024-09-20_N-PX_0001759354-24-000004.txt\n",
      "\n",
      "Processing: npx_filings\\2024-10-15_N-PX_A_0001438934-24-002005.txt\n",
      "\n",
      "Processing: npx_filings\\2024-11-12_N-PX_0001280604-24-000008.txt\n",
      "\n",
      "Processing: npx_filings\\2024-11-18_N-PX_0001908965-24-000006.txt\n",
      "\n",
      "Finished parsing N-PX.\n",
      "  Forms: 97\n",
      "  Proxy Voting Rows: 56865\n",
      "Saved form_npx.csv: 97 rows.\n",
      "Saved institutional_manager.csv: 19 rows.\n",
      "Saved series.csv: 34 rows.\n",
      "Saved proxy_voting_record.csv: 56865 rows.\n",
      "Saved matter_category.csv: 14 rows.\n",
      "Saved proxy_voting_record_category.csv: 57874 rows.\n",
      "Saved voting_record_manager.csv: 7077 rows.\n",
      "Saved voting_record_series.csv: 34336 rows.\n",
      "\n",
      "All CSVs have been written. Check your output folder to confirm.\n"
     ]
    }
   ],
   "source": [
    "run_all(\"npx_filings\", \"output\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
