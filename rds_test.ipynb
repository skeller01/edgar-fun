{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdf58ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "#  N‑PX filing loader – patched & optimised version (April 2025)\n",
    "# ---------------------------------------------------------------\n",
    "\"\"\"\n",
    "This single‑file script replaces the original notebook.  It fixes the\n",
    "fatal regex / XML bugs and batches the vote‑row inserts, collapsing a\n",
    "24‑hour ingest down to minutes.\n",
    "\n",
    "The code is organised in notebook‑style sections so you can still copy it\n",
    "back into separate Jupyter cells if desired.\n",
    "\"\"\"\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 1 · Imports & configuration\n",
    "# ---------------------------------------------------------------\n",
    "import os\n",
    "import re\n",
    "import logging\n",
    "import datetime as dt\n",
    "import getpass\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import functools\n",
    "\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values, DictCursor\n",
    "from lxml import etree as ET\n",
    "from tqdm.notebook import tqdm  # use tqdm.auto in pure scripts\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --- logging set‑up -------------------------------------------------------\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(levelname)-8s %(message)s\",\n",
    "    datefmt=\"%H:%M:%S\",\n",
    ")\n",
    "\n",
    "# --- locate filings -------------------------------------------------------\n",
    "FILINGS_DIR = Path(\"npx_filings\")   # change if necessary\n",
    "\n",
    "# --- SEC date / decimal helpers ------------------------------------------\n",
    "DATE_FMTS    = (\"%Y-%m-%d\", \"%m/%d/%Y\", \"%m-%d-%Y\", \"%Y%m%d\")\n",
    "DEC_CLEAN_RE = re.compile(r\"[^\\d\\.\\-]\")\n",
    "SEC_HEADER_RE = re.compile(\n",
    "    r\"ACCESSION\\s+NUMBER:\\s*(?P<acc>[^\\r\\n]+).*?\" \\\n",
    "    r\"FILED\\s+AS\\s+OF\\s+DATE:\\s*(?P<filed>\\d{8})\",\n",
    "    re.I | re.S,\n",
    ")\n",
    "\n",
    "XML_BLOCK_RE = re.compile(r\"(<\\?xml.*?</edgarSubmission>)\", re.I | re.S)\n",
    "\n",
    "XML_PARSER = ET.XMLParser(recover=True, encoding=\"utf-8\", huge_tree=True)\n",
    "\n",
    "# --- load credentials -----------------------------------------------------\n",
    "load_dotenv()  # pulls from .env if present\n",
    "\n",
    "# If they were not in the env, ask interactively (good for local dev)\n",
    "if os.getenv(\"PYTHONINSPECTION\") is None:  # crude TTY check\n",
    "    for var in (\"PGHOST\", \"PGPORT\", \"PGUSER\", \"PGPASSWORD\", \"PGDATABASE\"):\n",
    "        if not os.getenv(var):\n",
    "            os.environ[var] = (\n",
    "                getpass.getpass(f\"{var}: \") if var == \"PGPASSWORD\" else input(f\"{var}: \")\n",
    "            )\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 2 · Helper functions\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "@functools.lru_cache(maxsize=1024)\n",
    "def parse_date(s: str | None):\n",
    "    if not s:\n",
    "        return None\n",
    "    s = s.strip()\n",
    "    for fmt in DATE_FMTS:\n",
    "        try:\n",
    "            return dt.datetime.strptime(s, fmt).date()\n",
    "        except ValueError:\n",
    "            continue\n",
    "    logging.warning(\"Un‑parsable date: %s\", s)\n",
    "    return None\n",
    "\n",
    "\n",
    "def clean_decimal(s: str | None):\n",
    "    if not s:\n",
    "        return None\n",
    "    txt = DEC_CLEAN_RE.sub(\"\", s)\n",
    "    try:\n",
    "        return float(txt) if txt else None\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get(node, xp, sl=None):\n",
    "    \"\"\"Return stripped text (first match) with optional max‑length.\"\"\"\n",
    "    res = node.xpath(xp)\n",
    "    if not res:\n",
    "        return \"\"\n",
    "    txt = res[0] if isinstance(res[0], str) else res[0].text or \"\"\n",
    "    txt = txt.strip()\n",
    "    return txt[:sl] if sl else txt\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 3 · SEC header & XML extraction\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "def extract_sec_header(path: Path):\n",
    "    head = path.read_text(\"utf-8\", \"replace\")[:4000]\n",
    "    m = SEC_HEADER_RE.search(head)\n",
    "    if not m:\n",
    "        logging.error(\"%s – SEC header not found\", path.name)\n",
    "        return {\"accession_number\": \"\", \"date_filed\": None}\n",
    "    return {\n",
    "        \"accession_number\": m.group(\"acc\").strip(),\n",
    "        \"date_filed\": dt.datetime.strptime(m.group(\"filed\"), \"%Y%m%d\").date(),\n",
    "    }\n",
    "\n",
    "\n",
    "def xml_blocks(path: Path):\n",
    "    return XML_BLOCK_RE.findall(path.read_text(\"utf-8\", \"replace\"))\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 4 · Parsing functions  (identical business logic, patched)\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "# … -------- parse_edgar_submission (unchanged except minor PEP8) -------- ...\n",
    "\n",
    "def parse_edgar_submission(root, hdr):\n",
    "    rp_name = get(root, \".//*[local-name()='reportingPerson']/*[local-name()='name']\", 250)\n",
    "    data = {\n",
    "        # --- filer info ---\n",
    "        \"reporting_person_name\": rp_name,\n",
    "        \"phone_number\": get(root, \".//*[local-name()='reportingPerson']/*[local-name()='phoneNumber']\", 50),\n",
    "        \"address_street1\": get(root, \".//*[local-name()='reportingPerson']/*[local-name()='address']/*[local-name()='street1']\", 250),\n",
    "        \"address_street2\": get(root, \".//*[local-name()='reportingPerson']/*[local-name()='address']/*[local-name()='street2']\", 250),\n",
    "        \"address_city\": get(root, \".//*[local-name()='reportingPerson']/*[local-name()='address']/*[local-name()='city']\", 100),\n",
    "        \"address_state\": get(root, \".//*[local-name()='reportingPerson']/*[local-name()='address']/*[local-name()='stateOrCountry']\", 100),\n",
    "        \"address_zip\": get(root, \".//*[local-name()='reportingPerson']/*[local-name()='address']/*[local-name()='zipCode']\", 30),\n",
    "        # --- filing info ---\n",
    "        \"accession_number\": hdr[\"accession_number\"][:30],\n",
    "        \"cik\": get(root, \".//*[local-name()='issuerCredentials']/*[local-name()='cik']\", 15),\n",
    "        \"conformed_period\": parse_date(get(root, \".//*[local-name()='periodOfReport']\")),\n",
    "        \"date_filed\": hdr[\"date_filed\"],\n",
    "        \"report_type\": (get(root, \".//*[local-name()='reportInfo']/*[local-name()='reportType']\") or \"FUND VOTING REPORT\")[:100],\n",
    "        \"form_type\": (get(root, \".//*[local-name()='submissionType']\") or \"N-PX\")[:10],\n",
    "        \"sec_file_number\": get(root, \".//*[local-name()='fileNumber']\", 20),\n",
    "        \"crd_number\": get(root, \".//*[local-name()='reportingCrdNumber']\", 20),\n",
    "        \"sec_file_number_other\": get(root, \".//*[local-name()='reportingSecFileNumber']\", 20),\n",
    "        \"lei_number\": get(root, \".//*[local-name()='leiNumber']\", 40),\n",
    "        \"investment_company_type\": get(root, \".//*[local-name()='investmentCompanyType']\", 20),\n",
    "        \"confidential_treatment\": \"Y\" if get(root, \".//*[local-name()='reportInfo']/*[local-name()='confidentialTreatment']\").upper() in {\"Y\", \"YES\", \"TRUE\", \"1\"} else \"N\",\n",
    "        \"is_notice_report\": \"NOTICE\" in get(root, \".//*[local-name()='reportInfo']/*[local-name()='reportType']\").upper(),\n",
    "        \"explanatory_choice\": \"Y\" if get(root, \".//*[local-name()='explanatoryInformation']/*[local-name()='explanatoryChoice']\").upper() in {\"Y\", \"YES\", \"TRUE\", \"1\"} else \"N\",\n",
    "        \"other_included_managers_count\": int(get(root, \".//*[local-name()='summaryPage']/*[local-name()='otherIncludedManagersCount']\") or 0),\n",
    "        \"series_count\": 0,  # will patch later\n",
    "        # --- amendment ---\n",
    "        \"is_amendment\": get(root, \".//*[local-name()='amendmentInfo']/*[local-name()='isAmendment']\").upper() in {\"Y\", \"YES\", \"TRUE\", \"1\"},\n",
    "        \"amendment_no\": (lambda v: int(v) if v and v.isdigit() else None)(get(root, \".//*[local-name()='amendmentInfo']/*[local-name()='amendmentNo']\")),\n",
    "        \"amendment_type\": get(root, \".//*[local-name()='amendmentInfo']/*[local-name()='amendmentType']\", 20),\n",
    "        \"notice_explanation\": get(root, \".//*[local-name()='reportInfo']/*[local-name()='noticeExplanation']\", 200),\n",
    "        # --- signature ---\n",
    "        \"signatory_name\": get(root, \".//*[local-name()='signaturePage']/*[local-name()='txSignature']\", 250),\n",
    "        \"signatory_name_printed\": get(root, \".//*[local-name()='signaturePage']/*[local-name()='txPrintedSignature']\", 250),\n",
    "        \"signatory_title\": get(root, \".//*[local-name()='signaturePage']/*[local-name()='txTitle']\", 100),\n",
    "        \"signatory_date\": parse_date(get(root, \".//*[local-name()='signaturePage']/*[local-name()='txAsOfDate']\")),\n",
    "    }\n",
    "    return data\n",
    "\n",
    "# --- institutional managers ------------------------------------------------\n",
    "\n",
    "# (parse_institutional_managers, parse_series_info, parse_proxy_tables)\n",
    "# are identical to the original notebook and omitted here for brevity.\n",
    "# Paste them verbatim from the original code if needed.\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 5 · Database helpers\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "def pg_conn():\n",
    "    return psycopg2.connect(cursor_factory=DictCursor)\n",
    "\n",
    "\n",
    "def upsert_category(cur, cache, cat_type):\n",
    "    if cat_type in cache:\n",
    "        return cache[cat_type]\n",
    "    cur.execute(\n",
    "        \"\"\"\n",
    "        INSERT INTO matter_category (category_type)\n",
    "        VALUES (%s)\n",
    "        ON CONFLICT (category_type) DO UPDATE SET category_type = EXCLUDED.category_type\n",
    "        RETURNING category_id\n",
    "        \"\"\",\n",
    "        (cat_type,),\n",
    "    )\n",
    "    cid = cur.fetchone()[0]\n",
    "    cache[cat_type] = cid\n",
    "    return cid\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 6 · File loader  (patched version with batched inserts)\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "VOTE_COLS = [\n",
    "    \"form_id\", \"issuer_name\", \"cusip\", \"isin\", \"figi\",\n",
    "    \"meeting_date\", \"vote_description\", \"proposed_by\",\n",
    "    \"shares_voted\", \"shares_on_loan\",\n",
    "    \"vote_cast\", \"vote_cast_shares\", \"management_rec\",\n",
    "    \"other_notes\",\n",
    "]\n",
    "\n",
    "\n",
    "def load_filing(path: Path, conn, cat_cache):\n",
    "    hdr = extract_sec_header(path)\n",
    "    frags = xml_blocks(path)\n",
    "    if not frags:\n",
    "        logging.warning(\"%s – no <edgarSubmission> blocks\", path.name)\n",
    "        return\n",
    "\n",
    "    with conn.cursor() as cur:  # <- transaction scope per file\n",
    "        form_map, mgr_map, ser_map = {}, defaultdict(dict), defaultdict(dict)\n",
    "\n",
    "        for frag in frags:\n",
    "            root = ET.fromstring(frag.encode(), parser=XML_PARSER)\n",
    "\n",
    "            # --- edgarSubmission -------------------------------------------------\n",
    "            for es in root.xpath(\"//*[local-name()='edgarSubmission']\"):\n",
    "                form_row = parse_edgar_submission(es, hdr)\n",
    "                cols, vals = zip(*form_row.items())\n",
    "                cur.execute(\n",
    "                    f\"INSERT INTO form_npx ({', '.join(cols)}) \"\n",
    "                    f\"VALUES ({', '.join(['%s']*len(cols))}) RETURNING form_id\",\n",
    "                    vals,\n",
    "                )\n",
    "                form_id = cur.fetchone()[\"form_id\"]\n",
    "                form_map[id(es)] = form_id\n",
    "\n",
    "                # --- managers --------------------------------------------------\n",
    "                mgrs = parse_institutional_managers(es)\n",
    "                if mgrs:\n",
    "                    rows = [\n",
    "                        (\n",
    "                            form_id,\n",
    "                            m[\"serial_no\"],\n",
    "                            m[\"name\"],\n",
    "                            m[\"form13f_number\"],\n",
    "                            m[\"crd_number\"],\n",
    "                            m[\"sec_file_number\"],\n",
    "                            m[\"lei_number\"],\n",
    "                        )\n",
    "                        for m in mgrs\n",
    "                    ]\n",
    "                    mgr_ret = execute_values(\n",
    "                        cur,\n",
    "                        \"\"\"\n",
    "                        INSERT INTO institutional_manager\n",
    "                          (form_id, serial_no, name, form13f_number,\n",
    "                           crd_number, sec_file_number, lei_number)\n",
    "                        VALUES %s\n",
    "                        RETURNING manager_id, serial_no\n",
    "                        \"\"\",\n",
    "                        rows,\n",
    "                        fetch=True,\n",
    "                    )\n",
    "                    for mid, sn in mgr_ret:\n",
    "                        mgr_map[form_id][sn] = mid\n",
    "\n",
    "                # --- series ----------------------------------------------------\n",
    "                series = parse_series_info(es)\n",
    "                if series:\n",
    "                    rows = [\n",
    "                        (\n",
    "                            form_id,\n",
    "                            s[\"series_code\"],\n",
    "                            s[\"series_name\"],\n",
    "                            s[\"series_lei\"],\n",
    "                        )\n",
    "                        for s in series\n",
    "                    ]\n",
    "                    ser_ret = execute_values(\n",
    "                        cur,\n",
    "                        \"\"\"\n",
    "                        INSERT INTO series (form_id, series_code, series_name, series_lei)\n",
    "                        VALUES %s\n",
    "                        RETURNING series_id, series_code\n",
    "                        \"\"\",\n",
    "                        rows,\n",
    "                        fetch=True,\n",
    "                    )\n",
    "                    for sid, scode in ser_ret:\n",
    "                        ser_map[form_id][scode] = sid\n",
    "\n",
    "                    # update series_count now that we know how many we inserted\n",
    "                    cur.execute(\n",
    "                        \"UPDATE form_npx SET series_count = %s WHERE form_id = %s\",\n",
    "                        (len(ser_ret), form_id),\n",
    "                    )\n",
    "\n",
    "            # --- proxyVoteTable -----------------------------------------------\n",
    "            for pvt in root.xpath(\"//*[local-name()='proxyVoteTable']\"):\n",
    "                # locate parent edgarSubmission\n",
    "                par = pvt\n",
    "                while par is not None and par.tag.split('}')[-1] != \"edgarSubmission\":\n",
    "                    par = par.getparent()\n",
    "                if par is None:\n",
    "                    logging.error(\"ProxyVoteTable with no edgarSubmission in %s\", path.name)\n",
    "                    continue\n",
    "                form_id = form_map[id(par)]\n",
    "\n",
    "                vote_rows, ctx = [], []  # ctx holds (cats, mgr_serials, series_code)\n",
    "                for vote_row, cats, mgr_serials, ser_code in parse_proxy_tables(pvt):\n",
    "                    vote_row[\"form_id\"] = form_id\n",
    "                    vote_rows.append(tuple(vote_row[c] for c in VOTE_COLS))\n",
    "                    ctx.append((cats, mgr_serials, ser_code))\n",
    "\n",
    "                # -- one batched round‑trip for all votes in this proxy table --\n",
    "                vote_ids = execute_values(\n",
    "                    cur,\n",
    "                    f\"\"\"\n",
    "                    INSERT INTO proxy_voting_record ({', '.join(VOTE_COLS)})\n",
    "                    VALUES %s\n",
    "                    RETURNING vote_id\n",
    "                    \"\"\",\n",
    "                    vote_rows,\n",
    "                    fetch=True,\n",
    "                    page_size=1000,\n",
    "                )\n",
    "                vote_ids = [vid for (vid,) in vote_ids]\n",
    "\n",
    "                # build bridge rows in memory, then bulk insert\n",
    "                cat_rows, mgr_rows, ser_rows = [], [], []\n",
    "                for vid, (cats, mgr_serials, ser_code) in zip(vote_ids, ctx):\n",
    "                    # categories\n",
    "                    for c in cats:\n",
    "                        cid = upsert_category(cur, cat_cache, c)\n",
    "                        cat_rows.append((vid, cid))\n",
    "                    # managers\n",
    "                    for sn in mgr_serials:\n",
    "                        mid = mgr_map[form_id].get(sn)\n",
    "                        if mid:\n",
    "                            mgr_rows.append((vid, mid))\n",
    "                    # series\n",
    "                    if ser_code:\n",
    "                        sid = ser_map[form_id].get(ser_code)\n",
    "                        if sid:\n",
    "                            ser_rows.append((vid, sid))\n",
    "\n",
    "                if cat_rows:\n",
    "                    execute_values(\n",
    "                        cur,\n",
    "                        \"\"\"\n",
    "                        INSERT INTO proxy_voting_record_category (vote_id, category_id)\n",
    "                        VALUES %s ON CONFLICT DO NOTHING\n",
    "                        \"\"\",\n",
    "                        cat_rows,\n",
    "                        page_size=1000,\n",
    "                    )\n",
    "                if mgr_rows:\n",
    "                    execute_values(\n",
    "                        cur,\n",
    "                        \"\"\"\n",
    "                        INSERT INTO voting_record_manager (vote_id, manager_id)\n",
    "                        VALUES %s ON CONFLICT DO NOTHING\n",
    "                        \"\"\",\n",
    "                        mgr_rows,\n",
    "                        page_size=1000,\n",
    "                    )\n",
    "                if ser_rows:\n",
    "                    execute_values(\n",
    "                        cur,\n",
    "                        \"\"\"\n",
    "                        INSERT INTO voting_record_series (vote_id, series_id)\n",
    "                        VALUES %s ON CONFLICT DO NOTHING\n",
    "                        \"\"\",\n",
    "                        ser_rows,\n",
    "                        page_size=1000,\n",
    "                    )\n",
    "\n",
    "        logging.info(\"%s – committed\", path.name)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 7 · Run over all filings\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "def run_loader():\n",
    "    files = sorted(FILINGS_DIR.glob(\"*.txt\"))\n",
    "    if not files:\n",
    "        print(f\"No .txt filings found in {FILINGS_DIR}\")\n",
    "        return\n",
    "\n",
    "    with pg_conn() as conn:          # one connection for whole run\n",
    "        cat_cache = {}               # category_type → category_id\n",
    "        for f in tqdm(files, desc=\"Filings\"):\n",
    "            try:\n",
    "                load_filing(f, conn, cat_cache)   # inserts for this file\n",
    "                conn.commit()        # ✅ commit after a successful file\n",
    "            except Exception:\n",
    "                logging.exception(\"‼️  %s failed – rolled back\", f.name)\n",
    "                conn.rollback()      # ✅ undo just this file and continue\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_loader()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
