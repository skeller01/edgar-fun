{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'pandas' has no attribute '_pandas_parser_CAPI' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtime\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\skell\\Documents\\Projects\\edgar-fun\\venv\\lib\\site-packages\\pandas\\__init__.py:151\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomputation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;28meval\u001b[39m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    135\u001b[0m     concat,\n\u001b[0;32m    136\u001b[0m     lreshape,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    148\u001b[0m     qcut,\n\u001b[0;32m    149\u001b[0m )\n\u001b[1;32m--> 151\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m api, arrays, errors, io, plotting, tseries\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m testing\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_print_versions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m show_versions\n",
      "File \u001b[1;32mc:\\Users\\skell\\Documents\\Projects\\edgar-fun\\venv\\lib\\site-packages\\pandas\\api\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\" public toolkit API \"\"\"\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      3\u001b[0m     extensions,\n\u001b[0;32m      4\u001b[0m     indexers,\n\u001b[0;32m      5\u001b[0m     interchange,\n\u001b[0;32m      6\u001b[0m     types,\n\u001b[0;32m      7\u001b[0m     typing,\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m     10\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minterchange\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextensions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtyping\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\skell\\Documents\\Projects\\edgar-fun\\venv\\lib\\site-packages\\pandas\\api\\typing\\__init__.py:31\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwindow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     Expanding,\n\u001b[0;32m     21\u001b[0m     ExpandingGroupby,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     Window,\n\u001b[0;32m     27\u001b[0m )\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# TODO: Can't import Styler without importing jinja2\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# from pandas.io.formats.style import Styler\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjson\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_json\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m JsonReader\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StataReader\n\u001b[0;32m     34\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrameGroupBy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatetimeIndexResamplerGroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWindow\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     55\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\skell\\Documents\\Projects\\edgar-fun\\venv\\lib\\site-packages\\pandas\\io\\json\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjson\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_json\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     read_json,\n\u001b[0;32m      3\u001b[0m     to_json,\n\u001b[0;32m      4\u001b[0m     ujson_dumps,\n\u001b[0;32m      5\u001b[0m     ujson_loads,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjson\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_table_schema\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m build_table_schema\n\u001b[0;32m      9\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mujson_dumps\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mujson_loads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuild_table_schema\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\skell\\Documents\\Projects\\edgar-fun\\venv\\lib\\site-packages\\pandas\\io\\json\\_json.py:71\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjson\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_normalize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convert_to_line_delimits\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjson\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_table_schema\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     68\u001b[0m     build_table_schema,\n\u001b[0;32m     69\u001b[0m     parse_table_schema,\n\u001b[0;32m     70\u001b[0m )\n\u001b[1;32m---> 71\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparsers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m validate_integer\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     75\u001b[0m         Hashable,\n\u001b[0;32m     76\u001b[0m         Mapping,\n\u001b[0;32m     77\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\skell\\Documents\\Projects\\edgar-fun\\venv\\lib\\site-packages\\pandas\\io\\parsers\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparsers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     TextFileReader,\n\u001b[0;32m      3\u001b[0m     TextParser,\n\u001b[0;32m      4\u001b[0m     read_csv,\n\u001b[0;32m      5\u001b[0m     read_fwf,\n\u001b[0;32m      6\u001b[0m     read_table,\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      9\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextFileReader\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextParser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread_csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread_fwf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread_table\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\skell\\Documents\\Projects\\edgar-fun\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:32\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m using_copy_on_write\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m lib\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparsers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m STR_NA_VALUES\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     34\u001b[0m     AbstractMethodError,\n\u001b[0;32m     35\u001b[0m     ParserWarning,\n\u001b[0;32m     36\u001b[0m )\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decorators\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Appender\n",
      "File \u001b[1;32mparsers.pyx:1418\u001b[0m, in \u001b[0;36minit pandas._libs.parsers\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'pandas' has no attribute '_pandas_parser_CAPI' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "# edgar_npx_downloader.ipynb CONTENT\n",
    "#####################################\n",
    "\n",
    "# 1. Imports and Globals\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Configuration\n",
    "TARGET_YEAR = 2024\n",
    "MAX_DOWNLOADS = 10  # can be set to None for all\n",
    "MASTER_INDEX_DIR = \"./edgar_index\"\n",
    "NPX_DOWNLOAD_DIR = \"./npx_filings\"\n",
    "HEADERS = {\"User-Agent\": \"N-PX-Downloader (myemail@domain.com)\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Download Master Index Function\n",
    "def download_master_index(year: int, quarter: int, base_dir: str = MASTER_INDEX_DIR) -> str:\n",
    "    \"\"\"\n",
    "    Downloads the master index for the specified year & quarter.\n",
    "    Saves it locally as {base_dir}/{year}_QTR{quarter}_master.idx.\n",
    "    Returns the local filepath.\n",
    "    \"\"\"\n",
    "    url = f\"https://www.sec.gov/Archives/edgar/full-index/{year}/QTR{quarter}/master.idx\"\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "    local_filename = os.path.join(base_dir, f\"{year}_QTR{quarter}_master.idx\")\n",
    "\n",
    "    print(f\"Downloading: {url}\")\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "    if response.status_code == 200:\n",
    "        with open(local_filename, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Saved to: {local_filename}\")\n",
    "        return local_filename\n",
    "    else:\n",
    "        print(f\"Failed to retrieve {url} [HTTP {response.status_code}].\")\n",
    "        return \"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Parse Master Index\n",
    "def parse_master_index(idx_filepath: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parses a local .idx master index file and returns a DataFrame.\n",
    "    DataFrame columns: [cik, company_name, form_type, date_filed, filename].\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    if not os.path.exists(idx_filepath) or os.path.getsize(idx_filepath) == 0:\n",
    "        print(f\"Index file not found or empty: {idx_filepath}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    with open(idx_filepath, \"r\", encoding=\"latin-1\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Find the line with \"CIK|Company Name|Form Type|Date Filed|Filename\"\n",
    "    start_idx = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.strip().startswith(\"CIK|Company Name|Form Type|Date Filed|Filename\"):\n",
    "            start_idx = i + 1\n",
    "            break\n",
    "\n",
    "    if start_idx is None:\n",
    "        print(f\"Could not find the data header in: {idx_filepath}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Parse lines from start_idx onward\n",
    "    for line in lines[start_idx:]:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        parts = line.split(\"|\")\n",
    "        if len(parts) < 5:\n",
    "            continue\n",
    "        cik, company_name, form_type, date_filed, filename = parts[:5]\n",
    "        records.append({\n",
    "            \"cik\": cik,\n",
    "            \"company_name\": company_name,\n",
    "            \"form_type\": form_type,\n",
    "            \"date_filed\": date_filed,\n",
    "            \"filename\": filename\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Combine & Filter for N-PX\n",
    "def get_all_npx_for_year(year: int,\n",
    "                        base_dir: str = MASTER_INDEX_DIR,\n",
    "                        output_csv: str = \"npx_list.csv\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Downloads and parses the QTR1-QTR4 master indexes for the given year.\n",
    "    Filters for N-PX form types.\n",
    "    Saves combined results as a CSV: {base_dir}/{output_csv}.\n",
    "    Returns the N-PX DataFrame.\n",
    "    \"\"\"\n",
    "    combined_df = pd.DataFrame()\n",
    "\n",
    "    for quarter in [1, 2, 3, 4]:\n",
    "        idx_path = download_master_index(year, quarter, base_dir=base_dir)\n",
    "        if not idx_path:\n",
    "            # No file or failed download\n",
    "            continue\n",
    "        df_q = parse_master_index(idx_path)\n",
    "        if df_q.empty:\n",
    "            continue\n",
    "        combined_df = pd.concat([combined_df, df_q], ignore_index=True)\n",
    "\n",
    "    if combined_df.empty:\n",
    "        print(\"No data found for the entire year.\")\n",
    "        return combined_df\n",
    "\n",
    "    # Filter for N-PX only\n",
    "    mask_npx = combined_df[\"form_type\"].str.upper() == \"N-PX\"\n",
    "    npx_df = combined_df[mask_npx].copy()\n",
    "\n",
    "    # Save to CSV\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "    output_path = os.path.join(base_dir, output_csv)\n",
    "    npx_df.to_csv(output_path, index=False)\n",
    "    print(f\"Saved N-PX listings to {output_path}\")\n",
    "\n",
    "    return npx_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Aggregate N-PX for the Chosen Year\n",
    "npx_df = get_all_npx_for_year(\n",
    "    year=TARGET_YEAR,\n",
    "    base_dir=MASTER_INDEX_DIR,\n",
    "    output_csv=f\"npx_{TARGET_YEAR}_list.csv\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Download N-PX Filings\n",
    "def download_npx_filings(npx_df: pd.DataFrame,\n",
    "                         max_downloads: int = 10,\n",
    "                         output_dir: str = NPX_DOWNLOAD_DIR):\n",
    "    \"\"\"\n",
    "    Download up to 'max_downloads' N-PX filings from the npx_df.\n",
    "    Saves them to 'output_dir'.\n",
    "    \"\"\"\n",
    "    if npx_df.empty:\n",
    "        print(\"No N-PX filings in the DataFrame.\")\n",
    "        return\n",
    "\n",
    "    if max_downloads is None:\n",
    "        max_downloads = len(npx_df)\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    subset_df = npx_df.head(max_downloads)\n",
    "\n",
    "    count = 0\n",
    "    for idx, row in subset_df.iterrows():\n",
    "        filename = row[\"filename\"].strip()\n",
    "        form_type = row[\"form_type\"].strip()\n",
    "        date_filed = row[\"date_filed\"].strip()\n",
    "\n",
    "        full_url = f\"https://www.sec.gov/Archives/{filename}\"\n",
    "        local_name = f\"{date_filed}_{form_type}_{os.path.basename(filename)}\"\n",
    "        local_path = os.path.join(output_dir, local_name)\n",
    "\n",
    "        print(f\"\\n[{count+1}/{max_downloads}] Downloading: {full_url}\")\n",
    "        try:\n",
    "            r = requests.get(full_url, headers=HEADERS)\n",
    "            if r.status_code == 200:\n",
    "                with open(local_path, \"wb\") as f:\n",
    "                    f.write(r.content)\n",
    "                print(f\"Saved to: {local_path}\")\n",
    "            else:\n",
    "                print(f\"Failed to download [HTTP {r.status_code}].\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading {full_url}: {e}\")\n",
    "\n",
    "        count += 1\n",
    "        # Sleep 0.2s for ~5 requests/sec\n",
    "        time.sleep(0.2)\n",
    "\n",
    "    print(f\"\\nCompleted. Downloaded {count} files.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Execute the Download Step\n",
    "if not npx_df.empty:\n",
    "    download_npx_filings(\n",
    "        npx_df,\n",
    "        max_downloads=MAX_DOWNLOADS,\n",
    "        output_dir=NPX_DOWNLOAD_DIR\n",
    "    )\n",
    "else:\n",
    "    print(\"No N-PX data found for the specified year.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
